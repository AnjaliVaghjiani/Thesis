{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJ2IZnY0spOf",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Required libraries"
      ],
      "metadata": {
        "id": "2HXjH2crTOES"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zBB_GqePIUt"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers accelerate bitsandbytes gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8Eu1zo5Q2Z54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain faiss-cpu sentence-transformers"
      ],
      "metadata": {
        "id": "PaVHh0jR-kvv",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3t4w4p6nK9CL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Rag Database"
      ],
      "metadata": {
        "id": "WvKXyudfNNA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "vectorstore = FAISS.load_local(\n",
        "    \"/content/drive/MyDrive/rag_index\",\n",
        "    embeddings=embedding_model,\n",
        "    allow_dangerous_deserialization=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "DganfMFKEXxW",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data structure and Memory System"
      ],
      "metadata": {
        "id": "LV53MvRSxp2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime # Import datetime\n",
        "from typing import Dict, List\n",
        "import gradio as gr\n",
        "\n",
        "class SimpleDataManager:\n",
        "    \"\"\"Simple file-based storage for user data and recommendations\"\"\"\n",
        "\n",
        "    def __init__(self, data_dir=\"wellbeing_data\"):\n",
        "        self.data_dir = data_dir\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        os.makedirs(f\"{self.data_dir}/users\", exist_ok=True)\n",
        "        os.makedirs(f\"{self.data_dir}/recommendations\", exist_ok=True) # Corrected path\n",
        "\n",
        "    def save_user_week(self, user_id: str, week_data: Dict):\n",
        "        \"\"\"Save weekly data for a user\"\"\"\n",
        "        user_file = f\"{self.data_dir}/users/{user_id}.json\"\n",
        "\n",
        "        try:\n",
        "            # Load existing data\n",
        "            if os.path.exists(user_file):\n",
        "                with open(user_file, 'r+') as f:\n",
        "                    user_data = json.load(f)\n",
        "            else:\n",
        "                user_data = {\"user_id\": user_id, \"weeks\": []}\n",
        "\n",
        "            # Add new week\n",
        "            user_data[\"weeks\"].append(week_data)\n",
        "\n",
        "            # Keep only last 8 weeks\n",
        "            user_data[\"weeks\"] = user_data[\"weeks\"][-8:]\n",
        "\n",
        "            # Save\n",
        "            with open(user_file, 'w') as f:\n",
        "                json.dump(user_data, f, indent=2)\n",
        "\n",
        "            print(f\"‚úÖ Saved week data for user {user_id}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error saving user data: {str(e)}\")\n",
        "\n",
        "    def get_user_history(self, user_id: str) -> List[Dict]:\n",
        "        \"\"\"Get user's weekly history\"\"\"\n",
        "        user_file = f\"{self.data_dir}/users/{user_id}.json\"\n",
        "\n",
        "        try:\n",
        "            if os.path.exists(user_file):\n",
        "                with open(user_file, 'r') as f:\n",
        "                    user_data = json.load(f)\n",
        "                    history = user_data.get(\"weeks\", [])\n",
        "                    print(f\"üìä Retrieved {len(history)} weeks of history for {user_id}\")\n",
        "                    return history\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading user history: {str(e)}\")\n",
        "\n",
        "        return []\n",
        "\n",
        "    def save_recommendation(self, user_id: str, week_start: str, recommendation: str):\n",
        "        \"\"\"Save LLM recommendation\"\"\"\n",
        "        # Clean week_start for filename (remove invalid characters)\n",
        "        clean_week = week_start.replace(\"/\", \"-\").replace(\":\", \"-\")\n",
        "        rec_file = f\"{self.data_dir}/recommendations/{user_id}_{clean_week}.json\"\n",
        "\n",
        "        try:\n",
        "            rec_data = {\n",
        "                \"user_id\": user_id,\n",
        "                \"week_start\": week_start,\n",
        "                \"recommendation\": recommendation,\n",
        "                \"timestamp\": datetime.now().isoformat()\n",
        "            }\n",
        "\n",
        "            with open(rec_file, 'w') as f:\n",
        "                json.dump(rec_data, f, indent=2)\n",
        "\n",
        "            print(f\"‚úÖ Saved recommendation for user {user_id}, week {week_start}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error saving recommendation: {str(e)}\")\n",
        "\n",
        "    def get_last_recommendation(self, user_id: str) -> str:\n",
        "        \"\"\"Get user's last recommendation\"\"\"\n",
        "        rec_dir = f\"{self.data_dir}/recommendations\"\n",
        "\n",
        "        try:\n",
        "            # Check if recommendations directory exists\n",
        "            if not os.path.exists(rec_dir):\n",
        "                return \"\"\n",
        "\n",
        "            # Find latest recommendation file for this user\n",
        "            user_files = [f for f in os.listdir(rec_dir) if f.startswith(f\"{user_id}_\") and f.endswith('.json')]\n",
        "\n",
        "            if user_files:\n",
        "                # Sort by date and get latest\n",
        "                user_files.sort(reverse=True)\n",
        "                latest_file = f\"{rec_dir}/{user_files[0]}\"\n",
        "\n",
        "                with open(latest_file, 'r') as f:\n",
        "                    rec_data = json.load(f)\n",
        "                    recommendation = rec_data.get(\"recommendation\", \"\")\n",
        "                    print(f\"üìù Retrieved last recommendation for {user_id} ({len(recommendation)} chars)\")\n",
        "                    return recommendation\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading last recommendation: {str(e)}\")\n",
        "\n",
        "        return \"\"\n",
        "\n",
        "    def get_user_stats(self, user_id: str) -> Dict:\n",
        "        \"\"\"Get basic stats about user's data (bonus method)\"\"\"\n",
        "        history = self.get_user_history(user_id)\n",
        "\n",
        "        if not history:\n",
        "            return {\"total_weeks\": 0}\n",
        "\n",
        "        return {\n",
        "            \"total_weeks\": len(history),\n",
        "            \"first_week\": history[0].get(\"week_start\", \"Unknown\"),\n",
        "            \"latest_week\": history[-1].get(\"week_start\", \"Unknown\"),\n",
        "            \"avg_steps\": sum(week.get(\"total_steps\", 0) for week in history) // len(history),\n",
        "            \"avg_sleep\": sum(week.get(\"avg_sleep\", 0) for week in history) / len(history)\n",
        "        }"
      ],
      "metadata": {
        "id": "q9F2ra_wR8Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Well being LLM"
      ],
      "metadata": {
        "id": "qOWjDoksmrwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import re\n",
        "from typing import Dict, List\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "class WellbeingLLM:\n",
        "    \"\"\"Improved LLM system for wellbeing recommendations with better prompt engineering\"\"\"\n",
        "\n",
        "    def __init__(self, base_model_id: str, vectorstore_path: str = None):\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "        self.device = None\n",
        "        self.vectorstore = None\n",
        "        # data_manager is not defined in this class, it should be passed as an argument\n",
        "        # self.data_manager = data_manager\n",
        "\n",
        "        # Load vectorstore if path provided\n",
        "        if vectorstore_path:\n",
        "            self.load_vectorstore(vectorstore_path)\n",
        "\n",
        "        self.load_model(base_model_id)\n",
        "\n",
        "    def load_vectorstore(self, vectorstore_path: str):\n",
        "        \"\"\"Load FAISS vectorstore for RAG\"\"\"\n",
        "        try:\n",
        "            from langchain.vectorstores import FAISS\n",
        "            from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "            print(\"üìö Loading knowledge base...\")\n",
        "            embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "            self.vectorstore = FAISS.load_local(\n",
        "                vectorstore_path,\n",
        "                embeddings=embedding_model,\n",
        "                allow_dangerous_deserialization=True\n",
        "            )\n",
        "            print(\"‚úÖ Knowledge base loaded\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Could not load vectorstore: {e}\")\n",
        "            self.vectorstore = None\n",
        "\n",
        "    def load_model(self, model_path):\n",
        "        model_path = \"AnjaliNV/Merged_WellBeing_LLM_FP16\"\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_path,\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "        self.model.eval()\n",
        "        self.device = self.model.device # Set device after loading model\n",
        "        print(f\"‚úÖ LLM loaded successfully on {self.device}\")\n",
        "\n",
        "\n",
        "        # Master template builder with history\n",
        "    def build_template(self, current_week: dict, user_history: list = None) -> str: # Added self\n",
        "        demographics = current_week.get('demographics', {})\n",
        "        prefs = current_week.get('preferences', {})\n",
        "        food_data = current_week.get('food_data', {})\n",
        "\n",
        "        history_str = \"\"\n",
        "        if user_history:\n",
        "            history_lines = []\n",
        "            for i, past in enumerate(user_history[-3:], 1):  # limit to last 3 weeks\n",
        "                history_lines.append(f\"Week {-len(user_history)+i}: {json.dumps(past)}\")\n",
        "            history_str = \"\\n\\nPrevious weeks data and recommendations:\\n\" + \"\\n\".join(history_lines)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "    A user is a {demographics.get('sex', 'unknown')} aged {demographics.get('age', 'unknown')} years,\n",
        "    height {demographics.get('height', 'unknown')} cm, weight {demographics.get('weight', 'unknown')} kg.\n",
        "    Weekly stats: {current_week.get('total_steps',0):,} steps, {current_week.get('zone_minutes',0)} zone minutes,\n",
        "    {current_week.get('exercise_sessions',0)} exercise sessions, avg sleep {current_week.get('avg_sleep',0):.1f}h.\n",
        "    Diet: {prefs.get('diet_type','No Preference')}, Allergies: {', '.join(prefs.get('allergies',[])) if prefs.get('allergies') else 'none'}\n",
        "    Food consumption: Dairy {food_data.get('dairy_liters',0)}L, Legumes {food_data.get('legumes_grams',0)}g, Meat {food_data.get('meat_grams',0)}g,\n",
        "    Fruits {food_data.get('fruits_grams',0)}g, Vegetables {food_data.get('vegetables_grams',0)}g, Grains {food_data.get('grains_grams',0)}g,\n",
        "    Nuts {food_data.get('nuts_seeds_grams',0)}g, Water {food_data.get('water_liters',0)}L.\n",
        "    {history_str}\n",
        "\n",
        "    ---\n",
        "    **Provide structured health recommendations in this format**:\n",
        "    1) Food Recommendation\n",
        "    2) Physical Activity\n",
        "    3) Sleep & Well-being\n",
        "    4) Weekly Summary\n",
        "    \"\"\"\n",
        "        return prompt\n",
        "\n",
        "    def generate_recommendation(self, current_week: Dict, user_history: List[Dict] = None, last_recommendation: str = None) -> str:\n",
        "          \"\"\"Generate context-aware weekly recommendations\"\"\"\n",
        "\n",
        "          # Build prompt with current week + history + last recommendation\n",
        "          history_str = \"\"\n",
        "          if user_history:\n",
        "              last_weeks = user_history[-3:]  # last 3 weeks\n",
        "              for i, past_week in enumerate(last_weeks, 1):\n",
        "                  history_str += f\"Week {-len(last_weeks)+i}: {past_week}\\n\"\n",
        "\n",
        "          last_rec_str = f\"Last recommendation:\\n{last_recommendation}\\n\" if last_recommendation else \"\"\n",
        "\n",
        "          prompt = f\"\"\"\n",
        "  User weekly data:\n",
        "  {current_week}\n",
        "\n",
        "  {history_str}\n",
        "  {last_rec_str}\n",
        "\n",
        "  Please provide structured health recommendations in this format:\n",
        "  1) Food Recommendation\n",
        "  2) Physical Activity\n",
        "  3) Sleep & Well-being\n",
        "  4) Weekly Summary\n",
        "  \"\"\"\n",
        "\n",
        "          inputs = self.tokenizer(f\"<|user|>\\n{prompt}\\n<|assistant|>\\n\", return_tensors=\"pt\").to(self.model.device)\n",
        "\n",
        "          with torch.no_grad():\n",
        "              output_ids = self.model.generate(\n",
        "                  **inputs,\n",
        "                  max_new_tokens=1024,\n",
        "                  do_sample=True,\n",
        "                  temperature=0.7,\n",
        "                  top_p=0.9\n",
        "              )\n",
        "\n",
        "          response = self.tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "          return response.replace(prompt, \"\").strip()"
      ],
      "metadata": {
        "id": "Svqnq5QaerSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Well being system"
      ],
      "metadata": {
        "id": "ZJ-reNgcm3Id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List\n",
        "import torch\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime # Import datetime\n",
        "import gradio as gr\n",
        "\n",
        "class WellbeingSystem:\n",
        "    \"\"\"Main system that combines data management and LLM\"\"\"\n",
        "\n",
        "    def __init__(self, base_model_id: str, vectorstore_path: str = None):\n",
        "        self.data_manager = SimpleDataManager()\n",
        "        self.llm = WellbeingLLM(base_model_id, vectorstore_path) # Pass vectorstore_path to LLM\n",
        "        print(\"üéØ WellbeingSystem initialized\")\n",
        "\n",
        "    def analyze_and_recommend(self, user_id: str, week_data: Dict) -> str:\n",
        "        \"\"\"Main function: analyze weekly data and generate recommendations\"\"\"\n",
        "\n",
        "        print(f\"üìä Analyzing data for user: {user_id}\")\n",
        "\n",
        "        try:\n",
        "            # Get user history and last recommendation\n",
        "            user_history = self.data_manager.get_user_history(user_id)\n",
        "            last_recommendation = self.data_manager.get_last_recommendation(user_id)\n",
        "\n",
        "            print(f\"üìà Found {len(user_history)} weeks of history\")\n",
        "            if last_recommendation:\n",
        "                print(f\"üìù Previous recommendation found ({len(last_recommendation)} chars)\")\n",
        "\n",
        "            # Process current week data\n",
        "            processed_week = self._process_week_data(week_data)\n",
        "\n",
        "            # Show what data is being sent to LLM\n",
        "            print(f\"üìä Processed data: {processed_week['total_steps']:,} steps, {processed_week['zone_minutes']} zone mins, {processed_week['avg_sleep']:.1f}h sleep\")\n",
        "\n",
        "            # Generate recommendation using LLM\n",
        "            recommendation = self.llm.generate_recommendation(\n",
        "                processed_week, user_history, last_recommendation\n",
        "            )\n",
        "\n",
        "            # Save data (with error handling)\n",
        "            try:\n",
        "                self.data_manager.save_user_week(user_id, processed_week)\n",
        "                self.data_manager.save_recommendation(user_id, processed_week['week_start'], recommendation)\n",
        "                print(f\"üíæ Data saved successfully\")\n",
        "            except Exception as save_error:\n",
        "                print(f\"‚ö†Ô∏è Warning: Could not save data: {save_error}\")\n",
        "                # Continue anyway - return the recommendation even if saving fails\n",
        "\n",
        "            print(f\"‚úÖ Generated recommendation for {user_id} ({len(recommendation)} chars)\")\n",
        "            return recommendation\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error in analyze_and_recommend: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return f\"Analysis failed: {str(e)}. Please check your input data.\"\n",
        "\n",
        "    def _process_week_data(self, week_data: Dict) -> Dict:\n",
        "        \"\"\"Process and standardize weekly data with better validation\"\"\"\n",
        "\n",
        "        try:\n",
        "            # Parse sleep and mood data with validation\n",
        "            sleep_hours = week_data.get('sleep_hours', [])\n",
        "            mood_scores = week_data.get('mood_scores', [])\n",
        "\n",
        "            # Handle string input (comma-separated values)\n",
        "            if isinstance(sleep_hours, str):\n",
        "                try:\n",
        "                    sleep_hours = [float(x.strip()) for x in sleep_hours.split(',') if x.strip()]\n",
        "                except ValueError:\n",
        "                    print(\"‚ö†Ô∏è Invalid sleep hours format, using default\")\n",
        "                    sleep_hours = []\n",
        "\n",
        "            if isinstance(mood_scores, str):\n",
        "                try:\n",
        "                    mood_scores = [float(x.strip()) for x in mood_scores.split(',') if x.strip()]\n",
        "                except ValueError:\n",
        "                    print(\"‚ö†Ô∏è Invalid mood scores format, using default\")\n",
        "                    mood_scores = []\n",
        "\n",
        "            # Calculate averages with validation\n",
        "            avg_sleep = sum(sleep_hours) / len(sleep_hours) if sleep_hours else 0\n",
        "            avg_mood = sum(mood_scores) / len(mood_scores) if mood_scores else 0\n",
        "\n",
        "            # üöÄ ADD DEBUG:\n",
        "            print(f\"üîç DEBUG - Sleep calculation: {sleep_hours} ‚Üí avg: {avg_sleep}\")\n",
        "            print(f\"üîç DEBUG - Mood calculation: {mood_scores} ‚Üí avg: {avg_mood}\")\n",
        "\n",
        "            # Enhanced food data processing\n",
        "            food_data = self._process_food_data(week_data)\n",
        "\n",
        "            processed_data = {\n",
        "                'week_start': week_data.get('week_start', datetime.now().strftime('%Y-%m-%d')),\n",
        "                'total_steps': max(0, int(week_data.get('total_steps', 0))), # Ensure int and non-negative\n",
        "                'zone_minutes': max(0, int(week_data.get('zone_minutes', 0))), # Ensure int and non-negative\n",
        "                'exercise_sessions': max(0, int(week_data.get('exercise_sessions', 0))), # Ensure int and non-negative\n",
        "                'avg_sleep': round(avg_sleep, 1),\n",
        "                'avg_mood': round(avg_mood, 1),\n",
        "                'food_data': food_data,\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'demographics': week_data.get('demographics', {})\n",
        "            }\n",
        "\n",
        "\n",
        "            if 'preferences' in week_data:\n",
        "                processed_data['preferences'] = week_data['preferences']\n",
        "\n",
        "\n",
        "\n",
        "            return processed_data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing week data: {str(e)}\")\n",
        "            # Return empty or default data structure on error\n",
        "            return {\n",
        "                 'week_start': week_data.get('week_start', datetime.now().strftime('%Y-%m-%d')),\n",
        "                 'total_steps': 0,\n",
        "                 'zone_minutes': 0,\n",
        "                 'exercise_sessions': 0,\n",
        "                 'avg_sleep': 0.0,\n",
        "                 'avg_mood': 0.0,\n",
        "                 'food_data': {},\n",
        "                 'timestamp': datetime.now().isoformat(),\n",
        "                 'processing_error': str(e)\n",
        "            }\n",
        "\n",
        "\n",
        "    def _process_food_data(self, week_data: Dict) -> Dict:\n",
        "        \"\"\"Process food data handling both old and new formats\"\"\"\n",
        "\n",
        "        food_data = {}\n",
        "\n",
        "        # Check for new format first (with units)\n",
        "        unit_fields = ['dairy_liters', 'water_liters', 'legumes_grams', 'meat_grams',\n",
        "                      'fruits_grams', 'vegetables_grams', 'grains_grams', 'nuts_seeds_grams']\n",
        "\n",
        "        has_unit_format = any(field in week_data for field in unit_fields)\n",
        "\n",
        "        if has_unit_format:\n",
        "            print(\"üìä Using new format (with units)\")\n",
        "            # New format with units\n",
        "            for field in unit_fields:\n",
        "                value = week_data.get(field, 0)\n",
        "                try:\n",
        "                    food_data[field] = max(0, float(value))  # Ensure non-negative\n",
        "                except (ValueError, TypeError):\n",
        "                    food_data[field] = 0\n",
        "                    print(f\"‚ö†Ô∏è Invalid {field} value, using 0\")\n",
        "        else:\n",
        "            print(\"üìä Using old format (servings)\")\n",
        "            # Old format (for backward compatibility)\n",
        "            old_fields = ['dairy', 'legumes', 'meat', 'fruits', 'vegetables', 'grains', 'nuts_seeds', 'water_glasses']\n",
        "            for field in old_fields:\n",
        "                if field in week_data:\n",
        "                    try:\n",
        "                        food_data[field] = max(0, float(week_data[field]))\n",
        "                    except (ValueError, TypeError):\n",
        "                        food_data[field] = 0\n",
        "\n",
        "        return food_data"
      ],
      "metadata": {
        "id": "b75h28FTlLM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Well being app"
      ],
      "metadata": {
        "id": "94F3XlNDm99_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "from typing import Dict, List\n",
        "\n",
        "class WellbeingApp:\n",
        "    \"\"\"Complete Gradio interface with history and preferences (no targets)\"\"\"\n",
        "\n",
        "    def __init__(self, base_model_id: str):\n",
        "        print(\"üöÄ Initializing Complete WellbeingApp...\")\n",
        "        self.wellbeing_system = WellbeingSystem(\n",
        "            base_model_id,\n",
        "            vectorstore_path=\"/content/drive/MyDrive/rag_index\"\n",
        "        )\n",
        "\n",
        "    def create_wellbeing_app(self):\n",
        "        \"\"\"Create comprehensive Gradio interface with tabs\"\"\"\n",
        "\n",
        "        with gr.Blocks(title=\"üè• Complete Wellbeing LLM\", theme=gr.themes.Soft()) as demo:\n",
        "\n",
        "            gr.Markdown(\"# üè• Complete AI Wellbeing System\")\n",
        "            gr.Markdown(\"### Personalized health recommendations based on your current health data\")\n",
        "\n",
        "            # Create tabs for different sections\n",
        "            with gr.Tabs():\n",
        "\n",
        "                # TAB 1: MAIN ANALYSIS\n",
        "                with gr.TabItem(\"ü§ñ Get Recommendations\", elem_id=\"main-tab\"):\n",
        "                    self._create_main_analysis_tab()\n",
        "\n",
        "                # TAB 2: HISTORY REVIEW\n",
        "                with gr.TabItem(\"üìà Progress History\", elem_id=\"history-tab\"):\n",
        "                    self._create_history_tab()\n",
        "\n",
        "        return demo\n",
        "\n",
        "    def _create_main_analysis_tab(self):\n",
        "        \"\"\"Create the main analysis tab\"\"\"\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "\n",
        "                gr.Markdown(\"### ü§ñ AI Enhancement Options\")\n",
        "                # User Info Section\n",
        "                gr.Markdown(\"### üë§ User Information\")\n",
        "                user_id = gr.Textbox(label=\"üë§ User ID\", value=\"user_001\", info=\"Unique identifier for tracking your progress\")\n",
        "                week_start = gr.Textbox(label=\"üìÖ Week Start Date\", value=\"2024-01-15\", info=\"Format: YYYY-MM-DD\")\n",
        "\n",
        "                # Personal Details\n",
        "                sex = gr.Dropdown(\n",
        "                    label=\"‚ößÔ∏è Sex\",\n",
        "                    choices=[\"Male\", \"Female\"],\n",
        "                    value=\"Male\",\n",
        "                    info=\"Biological sex\"\n",
        "                )\n",
        "\n",
        "                age = gr.Number(\n",
        "                    label=\"üéÇ Age\",\n",
        "                    value=25,\n",
        "                    minimum=13,\n",
        "                    maximum=120,\n",
        "                    step=1,\n",
        "                    info=\"Age in years\"\n",
        "                )\n",
        "\n",
        "                weight = gr.Number(\n",
        "                    label=\"‚öñÔ∏è Weight (kg)\",\n",
        "                    value=70.0,\n",
        "                    minimum=30.0,\n",
        "                    maximum=300.0,\n",
        "                    step=0.1,\n",
        "                    info=\"Current weight in kilograms\"\n",
        "                )\n",
        "\n",
        "                height = gr.Number(\n",
        "                    label=\"üìè Height (cm)\",\n",
        "                    value=175.0,\n",
        "                    minimum=100.0,\n",
        "                    maximum=250.0,\n",
        "                    step=0.1,\n",
        "                    info=\"Height in centimeters\"\n",
        "                )\n",
        "\n",
        "                # Preferences Section\n",
        "                gr.Markdown(\"### üçΩÔ∏è Meal Preferences & Dietary Restrictions\")\n",
        "                with gr.Row():\n",
        "                    diet_type = gr.Dropdown(\n",
        "                        label=\"ü•ó Diet Type\",\n",
        "                        choices=[\n",
        "                            \"No Preference\", \"Vegetarian\", \"Vegan\", \"Pescatarian\",\n",
        "                            \"Keto\", \"Paleo\", \"Mediterranean\", \"Low Carb\", \"Gluten Free\", \"Dairy Free\"\n",
        "                        ],\n",
        "                        value=\"No Preference\",\n",
        "                        info=\"Select your primary dietary preference\"\n",
        "                    )\n",
        "\n",
        "                allergies = gr.CheckboxGroup(\n",
        "                    label=\"‚ö†Ô∏è Food Allergies & Intolerances\",\n",
        "                    choices=[\n",
        "                        \"Nuts (Tree nuts)\", \"Peanuts\", \"Shellfish\", \"Fish\",\n",
        "                        \"Milk/Dairy\", \"Eggs\", \"Soy\", \"Wheat/Gluten\",\n",
        "                        \"Sesame\", \"Lactose Intolerant\", \"Other\"\n",
        "                    ],\n",
        "                    info=\"‚ö†Ô∏è IMPORTANT: Select all allergies and intolerances\"\n",
        "                )\n",
        "\n",
        "                other_allergies = gr.Textbox(\n",
        "                    label=\"üö® Other Allergies/Restrictions\",\n",
        "                    placeholder=\"e.g., tomatoes, specific medications, religious restrictions...\",\n",
        "                    info=\"Specify any other dietary restrictions or allergies\"\n",
        "                )\n",
        "\n",
        "                # Activity Section\n",
        "                gr.Markdown(\"### üèÉ‚Äç‚ôÇÔ∏è Physical Activity\")\n",
        "                total_steps = gr.Number(label=\"Total Steps (Week)\", value=65000, info=\"Total steps for the week\")\n",
        "                zone_minutes = gr.Number(label=\"Zone Minutes (Week)\", value=120, info=\"Active zone minutes for the week\")\n",
        "                exercise_sessions = gr.Number(label=\"Exercise Sessions\", value=3, info=\"Number of exercise sessions this week\")\n",
        "\n",
        "                # Sleep & Mood Section\n",
        "                gr.Markdown(\"### üò¥ Sleep & Mood\")\n",
        "                sleep_hours = gr.Textbox(\n",
        "                    label=\"Sleep Hours (7 days)\",\n",
        "                    value=\"7.5,6.8,8.2,7.0,6.5,8.5,7.8\",\n",
        "                    info=\"Enter daily sleep hours separated by commas\"\n",
        "                )\n",
        "                mood_scores = gr.Textbox(\n",
        "                    label=\"Mood Scores (7 days)\",\n",
        "                    value=\"4,3.5,5,3,4,2.5,5\",\n",
        "                    info=\"Rate your daily mood from 1-5, separated by commas\"\n",
        "                )\n",
        "\n",
        "                # Food Section\n",
        "                gr.Markdown(\"### üçé Weekly Nutrition Intake\")\n",
        "                gr.Markdown(\"*Enter your total consumption for the entire week*\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    dairy = gr.Number(label=\"ü•õ Dairy (liters)\", value=3.5, info=\"Milk, yogurt, cheese\")\n",
        "                    water_liters = gr.Number(label=\"üíß Water (liters)\", value=48, info=\"Total water consumption for the week\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    fruits = gr.Number(label=\"üçé Fruits (grams)\", value=2100, info=\"Total fruit consumption for the week\")\n",
        "                    vegetables = gr.Number(label=\"ü•¨ Vegetables (grams)\", value=3500, info=\"Total vegetable consumption for the week\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    legumes = gr.Number(label=\"ü´ò Legumes (grams)\", value=350, info=\"Beans, lentils, peas\")\n",
        "                    nuts_seeds = gr.Number(label=\"ü•ú Nuts/Seeds (grams)\", value=210, info=\"Almonds, walnuts, chia seeds\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    meat = gr.Number(label=\"üçó Meat (grams)\", value=700, info=\"Chicken, beef, fish\")\n",
        "                    grains = gr.Number(label=\"üåæ Grains (grams)\", value=2800, info=\"Rice, bread, pasta, oats\")\n",
        "\n",
        "                # Action buttons\n",
        "                with gr.Row():\n",
        "                    analyze_btn = gr.Button(\"ü§ñ Get AI Recommendations\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "            with gr.Column():\n",
        "                main_output = gr.Markdown(\"\"\"\n",
        "    ### üè• Wellbeing Analysis Results\n",
        "    Click \"Get AI Recommendations\" to receive personalized health advice based on your data.\n",
        "                \"\"\")\n",
        "\n",
        "        # Store components\n",
        "        self.main_components = {\n",
        "            'user_id': user_id,\n",
        "            'week_start': week_start,\n",
        "            'sex': sex,\n",
        "            'age': age,\n",
        "            'weight': weight,\n",
        "            'height': height,\n",
        "            'total_steps': total_steps,\n",
        "            'zone_minutes': zone_minutes,\n",
        "            'exercise_sessions': exercise_sessions,\n",
        "            'sleep_hours': sleep_hours,\n",
        "            'mood_scores': mood_scores,\n",
        "            'dairy_liters': dairy,\n",
        "            'legumes_grams': legumes,\n",
        "            'meat_grams': meat,\n",
        "            'fruits_grams': fruits,\n",
        "            'vegetables_grams': vegetables,\n",
        "            'grains_grams': grains,\n",
        "            'nuts_seeds_grams': nuts_seeds,\n",
        "            'water_liters': water_liters,\n",
        "            'diet_type': diet_type,\n",
        "            'allergies': allergies,\n",
        "            'other_allergies': other_allergies,\n",
        "            'output': main_output\n",
        "        }\n",
        "\n",
        "        # Connect button\n",
        "        analyze_btn.click(\n",
        "            fn=self.analyze_wellbeing_with_preferences,\n",
        "            inputs=[\n",
        "                user_id, week_start, sex, age, weight, height,\n",
        "                total_steps, zone_minutes, exercise_sessions,\n",
        "                sleep_hours, mood_scores, dairy, legumes, meat,\n",
        "                fruits, vegetables, grains, nuts_seeds, water_liters,\n",
        "                diet_type, allergies, other_allergies\n",
        "            ],\n",
        "            outputs=[main_output]\n",
        "        )\n",
        "\n",
        "    def analyze_wellbeing_with_preferences(self, user_id, week_start, sex, age, weight, height,\n",
        "                                     total_steps, zone_minutes, exercise_sessions,\n",
        "                                     sleep_hours, mood_scores, dairy_liters, legumes_grams, meat_grams,\n",
        "                                     fruits_grams, vegetables_grams, grains_grams, nuts_seeds_grams, water_liters,\n",
        "                                     diet_type, allergies, other_allergies):\n",
        "        \"\"\"Enhanced analysis with user demographics and preferences\"\"\"\n",
        "\n",
        "        try:\n",
        "            # Input validation\n",
        "            if not user_id or not user_id.strip():\n",
        "                return \"‚ùå Error: Please enter a valid User ID\"\n",
        "\n",
        "            if not week_start:\n",
        "                return \"‚ùå Error: Please enter a week start date\"\n",
        "\n",
        "            # Validate demographic data\n",
        "            if age is not None and (age < 13 or age > 120):\n",
        "                return \"‚ùå Error: Please enter a valid age (13-120 years)\"\n",
        "\n",
        "            if weight is not None and (weight < 30 or weight > 300):\n",
        "                return \"‚ùå Error: Please enter a valid weight (30-300 kg)\"\n",
        "\n",
        "            if height is not None and (height < 100 or height > 250):\n",
        "                return \"‚ùå Error: Please enter a valid height (100-250 cm)\"\n",
        "\n",
        "            # Calculate BMI if weight and height are provided\n",
        "            bmi = None\n",
        "            if weight and height:\n",
        "                height_m = height / 100  # Convert cm to meters\n",
        "                bmi = round(weight / (height_m ** 2), 1)\n",
        "\n",
        "            # Prepare enhanced data with demographics\n",
        "            week_data = {\n",
        "                'user_id': user_id.strip(),\n",
        "                'week_start': week_start,\n",
        "                'demographics': {\n",
        "                    'sex': sex,\n",
        "                    'age': int(age) if age else None,\n",
        "                    'weight': float(weight) if weight else None,\n",
        "                    'height': float(height) if height else None,\n",
        "                    'bmi': bmi\n",
        "                },\n",
        "                'total_steps': max(0, int(total_steps)) if total_steps else 0,\n",
        "                'zone_minutes': max(0, int(zone_minutes)) if zone_minutes else 0,\n",
        "                'exercise_sessions': max(0, int(exercise_sessions)) if exercise_sessions else 0,\n",
        "                'sleep_hours': sleep_hours,\n",
        "                'mood_scores': mood_scores,\n",
        "                'dairy_liters': max(0, float(dairy_liters)) if dairy_liters else 0,\n",
        "                'legumes_grams': max(0, float(legumes_grams)) if legumes_grams else 0,\n",
        "                'meat_grams': max(0, float(meat_grams)) if meat_grams else 0,\n",
        "                'fruits_grams': max(0, float(fruits_grams)) if fruits_grams else 0,\n",
        "                'vegetables_grams': max(0, float(vegetables_grams)) if vegetables_grams else 0,\n",
        "                'grains_grams': max(0, float(grains_grams)) if grains_grams else 0,\n",
        "                'nuts_seeds_grams': max(0, float(nuts_seeds_grams)) if nuts_seeds_grams else 0,\n",
        "                'water_liters': max(0, float(water_liters)) if water_liters else 0,\n",
        "                'preferences': {\n",
        "                    'diet_type': diet_type,\n",
        "                    'allergies': allergies if allergies else [],\n",
        "                    'other_allergies': other_allergies.strip() if other_allergies else \"\"\n",
        "                }\n",
        "            }\n",
        "\n",
        "            recommendation = self.wellbeing_system.analyze_and_recommend(user_id.strip(), week_data)\n",
        "\n",
        "            # Format output without targets\n",
        "            output = self._format_analysis_output(week_data, recommendation)\n",
        "\n",
        "            return output\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Analysis error: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return f\"‚ùå Error: {str(e)}\\n\\nPlease check your input format and try again.\"\n",
        "\n",
        "    def _create_history_tab(self):\n",
        "        \"\"\"Create the history review tab\"\"\"\n",
        "\n",
        "        gr.Markdown(\"## üìà Progress History & Analytics\")\n",
        "        gr.Markdown(\"### Track your health journey and see improvements over time\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### üë§ User Selection\")\n",
        "                history_user_id = gr.Textbox(label=\"üë§ User ID\", value=\"user_001\", info=\"Enter user ID to view history\")\n",
        "\n",
        "                gr.Markdown(\"### üìä Analysis Options\")\n",
        "                analysis_type = gr.Radio(\n",
        "                    label=\"üìà View Type\",\n",
        "                    choices=[\n",
        "                        \"üìä Complete Progress Summary\",\n",
        "                        \"üìà Weekly Trends Analysis\",\n",
        "                        \"üìã Raw Data Export\",\n",
        "                        \"üèÜ Achievement Milestones\"\n",
        "                    ],\n",
        "                    value=\"üìä Complete Progress Summary\",\n",
        "                    info=\"Choose what type of analysis you want to see\"\n",
        "                )\n",
        "\n",
        "                weeks_to_show = gr.Slider(\n",
        "                    label=\"üìÖ Weeks to Include\",\n",
        "                    minimum=1,\n",
        "                    maximum=12,\n",
        "                    value=4,\n",
        "                    step=1,\n",
        "                    info=\"How many recent weeks to analyze\"\n",
        "                )\n",
        "\n",
        "                with gr.Row():\n",
        "                    view_history_btn = gr.Button(\"üìä View Progress\", variant=\"primary\", size=\"lg\")\n",
        "                    export_data_btn = gr.Button(\"üíæ Export Data\", variant=\"secondary\")\n",
        "                    delete_history_btn = gr.Button(\"üóëÔ∏è Clear History\", variant=\"stop\")\n",
        "\n",
        "            with gr.Column():\n",
        "                history_output = gr.Markdown(\"\"\"\n",
        "    ### üìà Progress History\n",
        "    Select a user and analysis type to view historical data and trends.\n",
        "                \"\"\")\n",
        "\n",
        "        # Store history components\n",
        "        self.history_components = {\n",
        "            'user_id': history_user_id,\n",
        "            'analysis_type': analysis_type,\n",
        "            'weeks_to_show': weeks_to_show,\n",
        "            'output': history_output\n",
        "        }\n",
        "\n",
        "    def _format_preferences_display(self, preferences: dict) -> str:\n",
        "        \"\"\"Format preferences for nice display\"\"\"\n",
        "\n",
        "        lines = [\"### üçΩÔ∏è Your Dietary Profile:\"]\n",
        "\n",
        "        # Diet type\n",
        "        if preferences.get('diet_type', 'No Preference') != \"No Preference\":\n",
        "            lines.append(f\"- **Diet:** {preferences['diet_type']}\")\n",
        "\n",
        "        # Allergies (most important!)\n",
        "        if preferences.get('allergies'):\n",
        "            allergy_list = \", \".join(preferences['allergies'])\n",
        "            lines.append(f\"- **‚ö†Ô∏è ALLERGIES:** {allergy_list}\")\n",
        "\n",
        "        if preferences.get('other_allergies'):\n",
        "            lines.append(f\"- **‚ö†Ô∏è OTHER RESTRICTIONS:** {preferences['other_allergies']}\")\n",
        "\n",
        "        if len(lines) == 1:  # Only the header\n",
        "            lines.append(\"- No specific dietary preferences set\")\n",
        "\n",
        "        return \"\\n\".join(lines)\n",
        "\n",
        "    def _format_analysis_output(self, week_data, recommendation):\n",
        "        \"\"\"Format analysis output without targets\"\"\"\n",
        "\n",
        "        daily_steps = week_data['total_steps'] / 7\n",
        "        daily_water = week_data['water_liters'] / 7\n",
        "\n",
        "        # Safely get avg_sleep and avg_mood with defaults\n",
        "        avg_sleep = week_data.get('avg_sleep', 0)\n",
        "        avg_mood = week_data.get('avg_mood', 0)\n",
        "\n",
        "        preferences_display = self._format_preferences_display(week_data['preferences'])\n",
        "\n",
        "        # Demographics display\n",
        "        demographics_info = \"\"\n",
        "        if week_data.get('demographics'):\n",
        "            demo = week_data['demographics']\n",
        "            if demo.get('bmi'):\n",
        "                demographics_info = f\"\\n### üë§ Health Profile:\\n- **BMI:** {demo['bmi']} (Height: {demo['height']}cm, Weight: {demo['weight']}kg)\"\n",
        "\n",
        "        return f\"\"\"# üè• Personalized Wellbeing Analysis & Recommendations\n",
        "\n",
        "## üë§ User: {week_data['user_id']} | üìÖ Week: {week_data['week_start']}\n",
        "\n",
        "{preferences_display}\n",
        "\n",
        "{demographics_info}\n",
        "\n",
        "### üìä Your Weekly Data Summary:\n",
        "**üèÉ‚Äç‚ôÇÔ∏è Activity:**\n",
        "- **Steps:** {week_data['total_steps']:,} ({daily_steps:.0f}/day)\n",
        "- **Zone Minutes:** {week_data['zone_minutes']}\n",
        "- **Exercise Sessions:** {week_data['exercise_sessions']}\n",
        "\n",
        "**üò¥ Sleep & Mood:**\n",
        "- **Sleep:** {week_data['sleep_hours']} hours daily\n",
        "- **Mood:** {week_data['mood_scores']}/10 daily scores\n",
        "\n",
        "**üçé Nutrition:**\n",
        "- ü•õ **Dairy:** {week_data['dairy_liters']:.1f}L | üíß **Water:** {week_data['water_liters']:.1f}L ({daily_water:.1f}L/day)\n",
        "- üçé **Fruits:** {week_data['fruits_grams']:.0f}g | ü•¨ **Vegetables:** {week_data['vegetables_grams']:.0f}g\n",
        "- ü´ò **Legumes:** {week_data['legumes_grams']:.0f}g | üçó **Meat:** {week_data['meat_grams']:.0f}g\n",
        "- üåæ **Grains:** {week_data['grains_grams']:.0f}g | ü•ú **Nuts/Seeds:** {week_data['nuts_seeds_grams']:.0f}g\n",
        "\n",
        "---\n",
        "\n",
        "## ü§ñ AI Recommendations\n",
        "*Personalized based on your current health data, preferences, and dietary restrictions*\n",
        "\n",
        "{recommendation}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "yMJif8UIexLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main execution"
      ],
      "metadata": {
        "id": "czFxU-C-nVSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment to run:\n",
        "app = WellbeingApp(base_model_id=\"AnjaliNV/Merged_WellBeing_LLM_FP16\")\n",
        "demo = app.create_wellbeing_app()\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "PK-nsLf7nPwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tuning"
      ],
      "metadata": {
        "id": "Vil6ywcR26VX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fine tune 1"
      ],
      "metadata": {
        "id": "sY3D0OlTv0Ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "from peft import PeftModel, LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "# --- Paths ---\n",
        "base_model_id = \"ContactDoctor/Bio-Medical-Llama-3-8B\"\n",
        "adapter_path = \"AnjaliNV/WellBeing_LLM\"  # previously trained LoRA adapter\n",
        "\n",
        "# --- Load tokenizer and base model ---\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        ")\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "model = PeftModel.from_pretrained(model, adapter_path)\n",
        "\n",
        "# --- Load new dataset ---\n",
        "dataset = load_dataset(\"AnjaliNV/Templete2\", split=\"train\")\n",
        "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
        "train_dataset = dataset['train']\n",
        "val_dataset = dataset['test']\n",
        "\n",
        "def format_prompt(example):\n",
        "    return {\n",
        "        \"text\": f\"<|user|>\\n{example['input']}\\n<|assistant|>\\n{example['output']}\"\n",
        "    }\n",
        "\n",
        "train_dataset = train_dataset.map(format_prompt)\n",
        "val_dataset = val_dataset.map(format_prompt)\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize, batched=True)\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "# --- Training arguments ---\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./diet-finetuned-model\",\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=5,  # you can choose fewer epochs since continuing training\n",
        "    learning_rate=2e-4,\n",
        "    bf16=True,\n",
        "    logging_dir=\"./logs\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    gradient_checkpointing=True,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "# --- Trainer ---\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "# --- Continue fine-tuning ---\n",
        "trainer.train()\n",
        "\n",
        "# --- Save updated LoRA adapter ---\n",
        "model.save_pretrained(adapter_path)\n",
        "tokenizer.save_pretrained(adapter_path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-bShTepJxc4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adapter_path = \"AnjaliNV/WellBeing_LLM\"\n",
        "model.push_to_hub(adapter_path, use_auth_token=True)\n",
        "tokenizer.push_to_hub(adapter_path, use_auth_token=True)"
      ],
      "metadata": {
        "id": "CvR6chF1650I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fine tuning domain Q and A"
      ],
      "metadata": {
        "id": "BdfkeMaosMMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel, PeftConfig, get_peft_model\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# 1Ô∏è‚É£ Load base model and tokenizer\n",
        "base_model_name = \"AnjaliNV/Wellbeing_coach\"  # e.g., a llama or bloom model\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_name,\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "# 2Ô∏è‚É£ Load existing LoRA adapter\n",
        "lora_model_path = \"AnjaliNV/WellBeing_LoRA\"\n",
        "model = PeftModel.from_pretrained(model, lora_model_path)\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "# 3Ô∏è‚É£ Load your dataset\n",
        "# Check available splits and use the first one\n",
        "dataset_dict = load_dataset(\"AnjaliNV/Custom_templete2\")\n",
        "first_split_name = list(dataset_dict.keys())[0]\n",
        "dataset = dataset_dict[first_split_name]\n",
        "\n",
        "\n",
        "# Preprocess as before\n",
        "def preprocess(example):\n",
        "    response = (\n",
        "        f\"Food Recommendation:\\n{example['food']}\\n\\n\"\n",
        "        f\"Physical Activity:\\n{example['fitness']}\\n\\n\"\n",
        "        f\"Sleep & Well-being:\\n{example['sleep_lifestyle']}\\n\\n\"\n",
        "        f\"Weekly Summary:\\n{example['overall']}\"\n",
        "    )\n",
        "    return {\"text\": f\"Instruction: {example['input']}\\nResponse: {response}\"}\n",
        "\n",
        "\n",
        "dataset = dataset.map(preprocess)\n",
        "\n",
        "def tokenize(batch):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        batch[\"text\"],\n",
        "        truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n",
        "    tokenized_inputs[\"labels\"] = tokenized_inputs[\"input_ids\"].clone() # Add labels for training\n",
        "    return tokenized_inputs\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
        "tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "# Create a PyTorch Dataset\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, tokenized_dataset):\n",
        "        self.tokenized_dataset = tokenized_dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokenized_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val).squeeze() if isinstance(val, list) else torch.tensor(val)\n",
        "                for key, val in self.tokenized_dataset[idx].items()}\n",
        "\n",
        "\n",
        "train_dataset = TextDataset(tokenized_dataset)\n",
        "\n",
        "\n",
        "# 4Ô∏è‚É£ Continue fine-tuning\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, padding=True, label_pad_token_id=tokenizer.pad_token_id) # Specify label_pad_token_id\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./WellBeing_LoRA_updated\",\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=8,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=3e-4,\n",
        "    fp16=True,\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    report_to=\"none\",\n",
        "    remove_unused_columns=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset, # Use the custom PyTorch Dataset\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "# Freeze base model, enable LoRA\n",
        "for name, param in model.named_parameters():\n",
        "    param.requires_grad = False\n",
        "for name, param in model.named_parameters():\n",
        "    if \"lora_\" in name:\n",
        "        param.requires_grad = True\n",
        "\n",
        "model.train()\n",
        "\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# 5Ô∏è‚É£ Save updated LoRA adapter only\n",
        "model.save_pretrained(\"./WellBeing_LoRA_updated\")\n",
        "tokenizer.save_pretrained(\"./WellBeing_LoRA_updated\")"
      ],
      "metadata": {
        "id": "yiE1AXzxS2AD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel\n",
        "\n",
        "base_model_name = \"AnjaliNV/Wellbeing_coach\"\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_name,\n",
        "    device_map=\"auto\",\n",
        "    load_in_4bit=True  # if your base model was loaded in 4-bit\n",
        ")\n",
        "# Load your merged adapter locally\n",
        "adapter_model = PeftModel.from_pretrained(base_model, \"./WellBeing_LoRA_updated\")\n",
        "\n",
        "# Push to your Hugging Face repo\n",
        "adapter_model.push_to_hub(\"AnjaliNV/WellBeing_LoRA\", use_auth_token=True)\n",
        "\n",
        "# Optionally, also push tokenizer updates\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./WellBeing_LoRA_updated\")\n",
        "tokenizer.push_to_hub(\"AnjaliNV/WellBeing_LoRA\", use_auth_token=True)\n"
      ],
      "metadata": {
        "id": "a5kIpu34etZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "\n",
        "base_model_name = \"AnjaliNV/Wellbeing_coach\"      # e.g. \"meta-llama/Llama-2-7b-hf\"\n",
        "adapter_path   = \"AnjaliNV/WellBeing_LoRA\"  # path or HF repo of your fine-tuned adapter\n",
        "merged_path    = \"AnjaliNV/WellBeing_merged_coach\"\n",
        "\n",
        "# 1. Load base model + adapter\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_name,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "model = PeftModel.from_pretrained(base_model, adapter_path)\n",
        "\n",
        "# 2. Merge LoRA weights into base model\n",
        "model = model.merge_and_unload()   # <-- key step\n",
        "\n",
        "# 3. Save merged model\n",
        "model.save_pretrained(merged_path, safe_serialization=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
        "tokenizer.save_pretrained(merged_path)\n",
        "\n",
        "print(f\"‚úÖ Merged model saved at {merged_path}\")\n"
      ],
      "metadata": {
        "id": "OBNuBXepY2k-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login, HfApi\n",
        "import os\n",
        "\n",
        "# 1. Log in to your Hugging Face account (paste your token from https://huggingface.co/settings/tokens)\n",
        "\n",
        "\n",
        "# 2. Define repo ID (new repo you want to create on Hugging Face)\n",
        "repo_id = \"AnjaliNV/WellBeing_merged_coach\"\n",
        "\n",
        "# 3. Create repo if it doesn‚Äôt exist already\n",
        "api = HfApi()\n",
        "api.create_repo(repo_id=repo_id, repo_type=\"model\", exist_ok=True)\n",
        "\n",
        "# 4. Upload your merged model folder\n",
        "local_dir = \"AnjaliNV/WellBeing_merged_coach\"  # the folder you saved earlier\n",
        "\n",
        "api.upload_folder(\n",
        "    repo_id=repo_id,\n",
        "    repo_type=\"model\",\n",
        "    folder_path=local_dir\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Model pushed successfully! Check it here: https://huggingface.co/{repo_id}\")"
      ],
      "metadata": {
        "id": "pCiintjwa0wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#test"
      ],
      "metadata": {
        "id": "iFZ_NxymQ614"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test base+adapter"
      ],
      "metadata": {
        "id": "JuhKg3-xN9_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "\n",
        "# 1Ô∏è‚É£ Load base model in 4-bit for memory efficiency\n",
        "base_model_name = \"AnjaliNV/Wellbeing_coach\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_name,\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# 2Ô∏è‚É£ Load LoRA adapter\n",
        "lora_path = \"./WellBeing_LoRA_updated\"\n",
        "model = PeftModel.from_pretrained(model, lora_path)\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "# 3Ô∏è‚É£ Function to generate response\n",
        "def generate_response(prompt, max_tokens=700, temperature=0.7, top_p=0.9):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    input_length = inputs.input_ids.shape[1]\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_tokens,\n",
        "            do_sample=True,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p\n",
        "        )\n",
        "    decoded = tokenizer.decode(output[0][input_length:], skip_special_tokens=True)\n",
        "    return decoded\n",
        "\n",
        "# 4Ô∏è‚É£ Gradio Interface\n",
        "iface = gr.Interface(\n",
        "    fn=generate_response,\n",
        "    inputs=[\n",
        "        gr.Textbox(lines=5, label=\"Instruction\"),\n",
        "        gr.Slider(50, 1024, value=700, step=1, label=\"Max Tokens\"),\n",
        "        gr.Slider(0.1, 1.0, value=0.7, step=0.05, label=\"Temperature\"),\n",
        "        gr.Slider(0.1, 1.0, value=0.9, step=0.05, label=\"Top-p Sampling\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"LLM Response\"),\n",
        "    title=\"Wellbeing Coach LoRA Adapter Test\",\n",
        "    description=\"Interactively test your fine-tuned LoRA adapter without merging it into the base model.\"\n",
        ")\n",
        "\n",
        "# 5Ô∏è‚É£ Launch interface\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "qNR9jkRNQ8Jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## merged model testing"
      ],
      "metadata": {
        "id": "jkBKywIENudh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "import re\n",
        "\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "\n",
        "#RAG-----------\n",
        "\n",
        "vectorstore = FAISS.load_local(\n",
        "    \"/content/drive/MyDrive/rag_index\",\n",
        "    embeddings=embedding_model,\n",
        "    allow_dangerous_deserialization=True\n",
        ")\n",
        "#---------------------\n",
        "\n",
        "# -------------------\n",
        "# Load merged model\n",
        "# -------------------\n",
        "model_path = \"AnjaliNV/WellBeing_Coach_LLM\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_path,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "print(next(model.parameters()).device)\n",
        "\n",
        "\n",
        "def chat_with_model(user_input):\n",
        "\n",
        "    docs = vectorstore.similarity_search(user_input, k=3)\n",
        "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "\n",
        "    # Inject the user_input into the prompt\n",
        "    prompt = f\"\"\"\n",
        "You are a professional well-being coach.\n",
        "Your role is to generate personalized well-being recommendations for the user.\n",
        "\n",
        "USER INPUT:\n",
        "{user_input}\n",
        "\n",
        "\n",
        "INSTRUCTIONS:\n",
        "- Always follow the official guidelines before making any recommendation.\n",
        "- Do NOT over-recommend. Keep suggestions safe, concise, and realistic. Ask user to simple avoid the contradit food with their diet prefernce.\n",
        "- Always take into account the user‚Äôs age, sex, and fitness history.\n",
        "- Stop immediately after completing section 5 (Weekly Summary).\n",
        "- Do NOT continue with further questions, explanations, or commentary.\n",
        "- Do NOT add any ‚ÄúAssistant:‚Äù or ‚ÄúHuman:‚Äù text.\n",
        "\n",
        "TASK:\n",
        "Based on the above user data, generate recommendations using EXACTLY the following structure:\n",
        "\n",
        "1) Food Recommendation\n",
        "- Overall Assessment: [...]\n",
        "- Areas of Improvements: [...]\n",
        "- Suggested Meals: [...]\n",
        "\n",
        "2) Physical Activity\n",
        "- Activity Assessment: [...]\n",
        "- Zone Minutes and Intensity Feedback: [...]\n",
        "- Strength/Cardio Tips: [Workout Suggestions]\n",
        "- Weekly Goals: [...]\n",
        "\n",
        "3) Sleep\n",
        "- Sleep Review: [...]\n",
        "- Sleep Suggestions: [...]\n",
        "\n",
        "4)Mood & Mental Health\n",
        "- Mood Review: [...]\n",
        "- Mental Health Suggestions: [...]\n",
        "\n",
        "5) Weekly Summary\n",
        "- Summary: [...]\n",
        "- Goals: [...]\n",
        "\"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    input_length = inputs.input_ids.shape[1]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=700,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            repetition_penalty=1.2,\n",
        "        )\n",
        "\n",
        "    # Decode response\n",
        "    response = tokenizer.decode(output_ids[0][input_length:], skip_special_tokens=True)\n",
        "    match = re.search(\n",
        "            r\"(1\\) Food Recommendation.*?5\\) Weekly Summary.*?)(?:\\n[A-Z][^:]|$)\",\n",
        "            response,\n",
        "            flags=re.DOTALL\n",
        "        )\n",
        "    if match:\n",
        "        clean_response = match.group(1).strip()\n",
        "    else:\n",
        "        clean_response = response.strip()\n",
        "    return response.strip()\n",
        "\n",
        "\n",
        "# -------------------\n",
        "# Gradio UI\n",
        "# -------------------\n",
        "iface = gr.Interface(\n",
        "    fn=chat_with_model,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\" WellBeing Coach\",\n",
        "    description=\"Ask questions about well-being.\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True, debug=True)\n"
      ],
      "metadata": {
        "id": "9rUzhMWvNwwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## cot check"
      ],
      "metadata": {
        "id": "hAp9KcTr5csf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from time import sleep\n",
        "from typing_extensions import final\n",
        "import gradio as gr\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings, SentenceTransformerEmbeddings\n",
        "from langchain.schema import Document\n",
        "import gc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# === Load FAISS vector store ===\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "vectorstore = FAISS.load_local(\n",
        "    \"/content/drive/MyDrive/rag_index\",\n",
        "    embeddings=embedding_model,\n",
        "    allow_dangerous_deserialization=True\n",
        ")\n",
        "\n",
        "foodstore = FAISS.load_local(\n",
        "    \"/content/drive/MyDrive/food_faiss_index\",\n",
        "    embeddings=embeddings,\n",
        "    allow_dangerous_deserialization=True\n",
        ")\n",
        "\n",
        "# === Load LLaMA 3 model with LoRA adapter ===\n",
        "model_path = \"AnjaliNV/Merged_WellBeing_LLM\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_path,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# === Define RAG-based response generation ===\n",
        "def generate_step(prompt, temperature=0.7, max_tokens=1024):\n",
        "    try:\n",
        "        print(f\"Generating response with prompt length: {len(prompt)}\")\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "        input_length = inputs.input_ids.shape[1]\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "              output_ids = model.generate(\n",
        "                  **inputs,\n",
        "                  max_new_tokens=max_tokens,\n",
        "                  do_sample=True,\n",
        "                  temperature=temperature,\n",
        "                  top_p=0.9,\n",
        "                  repetition_penalty=1.2\n",
        "              )\n",
        "\n",
        "        response = tokenizer.decode(output_ids[0][input_length:], skip_special_tokens=True)\n",
        "        print(f\"Generated response length: {len(response)}\")\n",
        "        return response.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in generate_step: {e}\")\n",
        "        return f\"Error generating response: {str(e)}\"\n",
        "\n",
        "def cleanup_gpu_memory():\n",
        "    \"\"\"Enhanced GPU memory cleanup\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "    gc.collect()\n",
        "\n",
        "def generate_with_cot(user_profile, temperature=0.3, max_tokens=512, k=3):\n",
        "\n",
        "    # search1 = f\"\"\"\n",
        "    # Using the given user_profile:\n",
        "    # {user_profile}\n",
        "    # 1) Find guideline and meal recommendations that match the user's dietary preference from user_profile.\n",
        "    # \"\"\"\n",
        "\n",
        "    # Retrieve relevant docs from vectorstore as context\n",
        "    docs = vectorstore.similarity_search(user_profile, k=k)\n",
        "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "    prompt1 = f\"\"\"\n",
        "USER PROFILE:\n",
        "{user_profile}\n",
        "CONTEXT: {context}\n",
        "--- END OF PROFILE ---\n",
        "You are a well-being coach. Consider the user's weekly data and guidance, and provide just a Food recommendation following the template below\n",
        "**1) Food Recommendation**\n",
        "- Overall Assessment: Write 2‚Äì3 sentences after carefully analysing the user‚Äôs food intake. Highlight inconsistencies, contradictions, and ensure alignment with diet preferences and allergies.\n",
        "- Areas of Improvement: for all meal intake categories, follow the comparison statement\n",
        "  - Comparison statement: \"Your weekly [food] intake of **X grams** is below/above the recommended **Y grams**, which is equivalent to **Z grams per day** and **B grams per week**.\"\n",
        "- Suggested Meals: Suggest 3‚Äì4 meals that directly address deficiencies. Always provide ingredient quantities (grams/ml) and align with the user‚Äôs dietary preferences and restrictions.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    food_response  = generate_step(prompt1, temperature=0.7, max_tokens=350)\n",
        "    print(f\"Food response:\\n {food_response}\")\n",
        "\n",
        "\n",
        "    prompt2 = f\"\"\"\n",
        "SYSTEM INSTRUCTION:\n",
        "You are a certified physical activity and fitness coach.\n",
        "- Your suggestions must be safe and healthy.\n",
        "- Encourage a balance of cardiovascular, strength, and flexibility exercises.\n",
        "- Always consider the user's fitness level.\n",
        "- Do not suggest excessive exercise.\n",
        "- Tell them to rest and recover.\n",
        "- Recommend stretching before and after workouts.\n",
        "- Always consider any past injuries.\n",
        "\n",
        "\n",
        "USER PROFILE:\n",
        "{user_profile}\n",
        "--- END OF PROFILE ---\n",
        "\n",
        "TASK:\n",
        "Using the USER PROFILE, generate a structured response for **Physical Activity**.\n",
        "Strictly follow the template below. Do not add extra commentary or change section headings.\n",
        "\n",
        "TEMPLATE (must be followed exactly):\n",
        "\n",
        "**2) Physical Activity**\n",
        "- Activity Assessment: Write 2‚Äì3 sentences evaluating the user‚Äôs current activity level (steps, sessions, or general lifestyle). Mention consistency with their nutrition if relevant.\n",
        "- Zone Minutes and Intensity Feedback: Provide recommended weekly zone minutes (moderate/vigorous). Suggest safe ways to gradually adjust exercise intensity.\n",
        "- Strength/Cardio Tips: Suggest 2‚Äì3 specific exercises with structure. Format as: \"Exercise name: X sets of Y reps, Z times per week.\" Include both cardio and strength. Always add warm-up (5‚Äì10 min dynamic stretch) and cool-down (5‚Äì10 min static stretch).\n",
        "- Weekly Goals: List 3‚Äì4 measurable and realistic activity goals. Each must include frequency and duration (e.g., \"Add 1 extra strength session per week\" or \"Walk 6,000 steps daily\").\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "    physical_response  = generate_step(prompt2, temperature=0.7, max_tokens=350)\n",
        "    print(f\"Physical response:\\n {physical_response}\")\n",
        "\n",
        "    prompt3 = f\"\"\"\n",
        "      USER PROFILE:\n",
        "      {user_profile}\n",
        "      --- END OF PROFILE ---\n",
        "\n",
        "      TASK:\n",
        "      Using the USER PROFILE, generate a structured response for **Sleep, Mood, Lifestyle, and Social Health**.\n",
        "      Strictly follow the template. Do not add extra commentary or change section headings.\n",
        "\n",
        "      TEMPLATE (must be followed exactly):\n",
        "\n",
        "      **3) Sleep & Mood**\n",
        "      - Sleep and Mood Review: Write 3‚Äì4 sentences analyzing the user‚Äôs current sleep patterns, duration, quality, and mood. Highlight connections to lifestyle, diet, or activity if relevant.\n",
        "      - Suggestions: Provide 4‚Äì5 actionable recommendations to improve sleep quality, mood, and overall well-being. Include measurable tips such as bedtime routines, relaxation techniques, sleep timing consistency, dietary timing, mindfulness practices, or social engagement strategies.\n",
        "\"\"\"\n",
        "\n",
        "    sleep_response  = generate_step(prompt3, temperature=0.7, max_tokens=200)\n",
        "    print(f\"Sleep response:\\n {sleep_response}\")\n",
        "\n",
        "    prompt4 = f\"\"\"\n",
        "USER PROFILE:\n",
        "{user_profile}\n",
        "--- END OF PROFILE ---\n",
        "\n",
        "TASK:\n",
        "Using the USER PROFILE and any context available, generate a structured **Weekly Summary** that highlights strengths, areas for improvement, and actionable goals.\n",
        "Strictly follow the template. Do not add extra commentary or change section headings.\n",
        "\n",
        "TEMPLATE (must be followed exactly):\n",
        "\n",
        "**4) Weekly Summary**\n",
        "- Summary: Write 2‚Äì3 sentences highlighting the user‚Äôs current well-being strengths, noting areas for improvement across food, physical activity, sleep, and mood.\n",
        "- Goals: Provide 3‚Äì5 specific, measurable, and realistic goals for the upcoming week. Each goal should directly relate to food, exercise, sleep, or overall well-being, e.g., daily servings of fruits/vegetables, step count targets, hydration goals, sleep routines, or structured exercise sessions.\n",
        "\"\"\"\n",
        "\n",
        "    overall_response = generate_step(prompt4, temperature=0.7, max_tokens=200)\n",
        "    print(f\"overall response:\\n {overall_response}\")\n",
        "\n",
        "    #     cleanup_gpu_memory()\n",
        "    final_response = f\"{food_response}\\n\\n{physical_response}\\n\\n{sleep_response}\\n\\n{overall_response}\"\n",
        "\n",
        "    return final_response\n",
        "\n",
        "# === Gradio UI ===\n",
        "iface = gr.Interface(\n",
        "    fn=generate_with_cot,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"RAG-Powered WellBeing Chatbot\",\n",
        "    description=\"Ask questions about well-being. The bot uses both fine-tuned LLaMA model + RAG retrieval for grounded answers.\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True, debug=True)\n"
      ],
      "metadata": {
        "id": "cFbj0sVz5e5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data generation"
      ],
      "metadata": {
        "id": "JYoTiJQ7G9SR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json, re, time\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=\"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\")\n",
        "\n",
        "\n",
        "# ---------- Utilities ----------\n",
        "def clean_json_output(text: str):\n",
        "    m = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
        "    if not m:\n",
        "        return None\n",
        "    s = m.group(0)\n",
        "    # small cleanups\n",
        "    s = s.replace('\\\\\"', '\"')\n",
        "    try:\n",
        "        return json.loads(s)\n",
        "    except json.JSONDecodeError:\n",
        "        return None\n",
        "\n",
        "import re\n",
        "\n",
        "\n",
        "\n",
        "def call_llm_json(prompt, temperature=0.6, max_tokens=650, retries=2):\n",
        "    for i in range(retries):\n",
        "        try:\n",
        "            # If your SDK supports json_object, uncomment this for stricter JSON:\n",
        "            # resp = client.chat.completions.create(\n",
        "            #     model=\"gpt-4o-mini\",\n",
        "            #     messages=[{\"role\":\"user\",\"content\":prompt}],\n",
        "            #     temperature=temperature,\n",
        "            #     max_tokens=max_tokens,\n",
        "            #     response_format={\"type\":\"json_object\"}\n",
        "            # )\n",
        "            resp = client.chat.completions.create(\n",
        "                model=\"gpt-4o-mini\",\n",
        "                messages=[{\"role\":\"user\",\"content\":prompt}],\n",
        "                temperature=temperature,\n",
        "                max_tokens=max_tokens\n",
        "            )\n",
        "            raw = resp.choices[0].message.content.strip()\n",
        "            js = clean_json_output(raw)\n",
        "            if js is not None:\n",
        "                return js\n",
        "            # fallback: return raw if still not JSON\n",
        "            if i == retries - 1:\n",
        "                return {\"_raw\": raw}\n",
        "        except Exception as e:\n",
        "            if i == retries - 1:\n",
        "                return {\"_error\": str(e)}\n",
        "            time.sleep(0.7)\n",
        "\n",
        "def row_to_profile_text(row):\n",
        "    return f\"\"\"Demographics: Gender({row['gender']}), Age({row['age']}), Height({row['height_cm']} cm), Weight({row['weight_kg']} kg), BMI({row['bmi']})\n",
        "Physical Activity: Weekly Steps({row['weekly_steps']}), Zone Minutes per week({row['zone_minutes']}), Exercise Sessions per week({row['exercise_sessions']}))\n",
        "Sleep: Average hours per night({row['hours_sleep']})\n",
        "Dietary Preference: Declared Diet({row['Declared_Diet']}), Allergies({row['Allergies']})\n",
        "Weekly Food Consumption: Dairy({row['Dairy_liters']} L), Legumes({row['Legumes_grams']} g), Meat({row['Meat_grams']} g), Fruits({row['Fruits_grams']} g), Vegetables({row['Vegetables_grams']} g), Grains({row['Grains_grams']} g), Nuts({row['Nuts_grams']} g), Water({row['hydration_level']} L)\"\"\"\n",
        "\n",
        "def assemble_report(food, activity, sleep, summary):\n",
        "    # Convert section JSONs into your exact final text format\n",
        "    def get(d, k, default=\"\"):\n",
        "        return d.get(k, default) if isinstance(d, dict) else default\n",
        "\n",
        "    # Food section (optional: omit if you‚Äôre not generating food in a given run)\n",
        "    food_text = f\"\"\"**1) Food Recommendation**\n",
        "- Overall Assessment: {get(food,'overall_assessment')}\n",
        "- Areas of Improvements: {get(food,'areas_of_improvement')}\n",
        "- Suggested Meals: {get(food,'suggested_meals')}\"\"\"\n",
        "\n",
        "    activity_text = f\"\"\"**2) Physical Activity**\n",
        "- Activity Assessment: {get(activity,'activity_assessment')}\n",
        "- Zone Minutes and Intensity Feedback: {get(activity,'zone_minutes_feedback')}\n",
        "- Strength/Cardio Tips: {get(activity,'strength_cardio_tips')}\n",
        "- Weekly Goals: {get(activity,'weekly_goals')}\"\"\"\n",
        "\n",
        "    sleep_text = f\"\"\"**3) Sleep & Well-being**\n",
        "- Sleep Review: {get(sleep,'sleep_review')}\n",
        "- Suggestions: {get(sleep,'suggestions')}\"\"\"\n",
        "\n",
        "    summary_text = f\"\"\"**4) Weekly Summary**\n",
        "- Summary: {get(summary,'summary')}\n",
        "- Goals: {get(summary,'goals')}\"\"\"\n",
        "\n",
        "    return \"\\n\\n\".join([food_text, activity_text, sleep_text, summary_text])\n",
        "\n",
        "# ---------- Prompts (section-by-section) ----------\n",
        "def prompt_food(profile_text):\n",
        "    return f\"\"\"\n",
        "You are a nutrition coach. Speak directly to the person (use \"you\" / \"your\") instead of saying \"the user\".\n",
        "\n",
        "Based ONLY on this profile:\n",
        "\n",
        "{profile_text}\n",
        "\n",
        "Return JSON with keys:\n",
        "{{\n",
        "  \"overall_assessment\": \"Analyze your data and weekly food intake to identify any inconsistencies, contradictions, or nutritional deficiencies in your diet.\",\n",
        "  \"areas_of_improvement\": \"Each item names a low-intake group and a concrete weekly target with units. Also if you are consuming high quantity of some food then recommend reducing it.\",\n",
        "  \"suggested_meals\": \"When identifying food deficiencies (e.g., low fruit intake), list a few specific examples of foods rich in the missing nutrients (e.g., oranges for Vitamin C). After highlighting these foods, provide practical meal recommendations that incorporate them.\"\n",
        "}}\n",
        "Return ONLY JSON.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def prompt_activity(profile_text, food_json):\n",
        "    return f\"\"\"\n",
        "You are a fitness coach. Speak directly to the person (use \"you\" / \"your\").\n",
        "\n",
        "PROFILE:\n",
        "{profile_text}\n",
        "\n",
        "FOOD CONTEXT (JSON):\n",
        "{json.dumps(food_json, ensure_ascii=False)}\n",
        "\n",
        "Return JSON with keys:\n",
        "{{\n",
        "  \"activity_assessment\": \"Analyze your total weekly steps, exercise sessions, and physical data, taking into account your meal intake and overall lifestyle. Identify strengths and areas needing improvement.\",\n",
        "  \"zone_minutes_feedback\": \"Evaluate your current zone minutes and exercise intensity. Provide suggestions to increase or decrease intensity or duration as appropriate.\",\n",
        "  \"strength_cardio_tips\": \"Recommend specific strength and cardio exercises tailored to you, including sets, reps, frequency, and exercise type (e.g., 5 sets of squats twice a day).\"\n",
        "  \"weekly_goals\": \"Food Options: For each deficiency or area of improvement, suggest 2‚Äì3 specific food examples that address the gap (e.g., ‚ÄúFor protein: lentils, tofu, seitan. For Vitamin C: oranges, kiwi, bell peppers.‚Äù).\n",
        "                    Meal Recommendations: After listing the food options, provide 2‚Äì3 complete meal ideas that incorporate these foods (e.g., ‚ÄúQuinoa salad with black beans, avocado, and corn.‚Äù).\"\n",
        "}}\n",
        "Return ONLY JSON.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def prompt_sleep(profile_text, food_json, activity_json):\n",
        "    return f\"\"\"\n",
        "You are a sleep & recovery coach. Speak directly to the person (use \"you\" / \"your\").\n",
        "Use profile + FOOD + ACTIVITY context.\n",
        "\n",
        "PROFILE:\n",
        "{profile_text}\n",
        "\n",
        "FOOD CONTEXT:\n",
        "{json.dumps(food_json, ensure_ascii=False)}\n",
        "\n",
        "ACTIVITY CONTEXT:\n",
        "{json.dumps(activity_json, ensure_ascii=False)}\n",
        "\n",
        "Return JSON with keys:\n",
        "{{\n",
        "  \"sleep_review\": \"Analyze your average sleep hours and mood patterns. Identify any correlations between your diet, lifestyle, and sleep quality.\",\n",
        "  \"suggestions\": \"Provide actionable recommendations or activities to improve your sleep quality and mood, tailored to your habits and lifestyle.\"\n",
        "}}\n",
        "Return ONLY JSON.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def prompt_summary(profile_text, food_json, activity_json, sleep_json):\n",
        "    return f\"\"\"\n",
        "Create a SHORT weekly wrap-up that stitches FOOD + ACTIVITY + SLEEP into an actionable plan.\n",
        "Speak directly to the person (use \"you\" / \"your\").\n",
        "\n",
        "PROFILE:\n",
        "{profile_text}\n",
        "\n",
        "FOOD:\n",
        "{json.dumps(food_json, ensure_ascii=False)}\n",
        "\n",
        "ACTIVITY:\n",
        "{json.dumps(activity_json, ensure_ascii=False)}\n",
        "\n",
        "SLEEP:\n",
        "{json.dumps(sleep_json, ensure_ascii=False)}\n",
        "\n",
        "Return JSON with keys:\n",
        "{{\n",
        "  \"summary\": \"Write 2‚Äì3 sentences only. Keep it concise, focus on the *big picture*. Address the person as 'you'.\",\n",
        "  \"goals\": \"List 3‚Äì5 top goals max. Each goal ‚â§15 words, clearly actionable, written as 'your goals' or 'you should'. Example: 'Increase your daily steps to 8k'.\"\n",
        "}}\n",
        "Return ONLY JSON.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# ---------- One-row pipeline ----------\n",
        "def generate_full_report_for_row(row):\n",
        "    profile_text = row_to_profile_text(row)\n",
        "\n",
        "    food = call_llm_json(prompt_food(profile_text), temperature=0.7)\n",
        "    activity = call_llm_json(prompt_activity(profile_text, food), temperature=0.7)\n",
        "    sleep = call_llm_json(prompt_sleep(profile_text, food, activity), temperature=0.7)\n",
        "    weekly_summary = call_llm_json(prompt_summary(profile_text, food, activity, sleep), temperature=0.6)\n",
        "\n",
        "    final_text = assemble_report(food, activity, sleep, weekly_summary)\n",
        "\n",
        "    return {\n",
        "        \"input\": profile_text,\n",
        "        \"output\": final_text\n",
        "    }\n",
        "\n",
        "# ---------- Example: run for first 5 rows ----------\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    weekly_df = pd.read_csv(\"/content/train_sample_enriched_random (1).csv\")\n",
        "    sample = weekly_df.iloc[1700:2000]   # control how many to generate\n",
        "\n",
        "    output_path = \"diet_dataset_stepwise.jsonl\"\n",
        "\n",
        "    # Open file once in append mode\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for i, (_, row) in enumerate(sample.iterrows(), 1):\n",
        "            item = generate_full_report_for_row(row)\n",
        "\n",
        "            # Write immediately\n",
        "            f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "            # Flush every 10 rows so data is guaranteed saved\n",
        "            if i % 10 == 0:\n",
        "                f.flush()\n",
        "                os.fsync(f.fileno())  # ensure OS flush\n",
        "                print(f\"‚úÖ Saved {i} rows so far...\")\n"
      ],
      "metadata": {
        "id": "7g8iy5YrL_0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Dataset, concatenate_datasets\n",
        "import pandas as pd\n",
        "\n",
        "from datasets import load_dataset, Dataset, concatenate_datasets\n",
        "import json\n",
        "\n",
        "# üîπ Path to your generated JSONL file\n",
        "data_path = \"diet_dataset_stepwise.jsonl\"\n",
        "\n",
        "# Load your new dataset from JSONL\n",
        "new_dataset = load_dataset(\"json\", data_files=data_path, split=\"train\")\n",
        "\n",
        "# (Optional) Load existing dataset from Hub\n",
        "existing_dataset = load_dataset(\"AnjaliNV/Templete2\", split=\"train\")\n",
        "\n",
        "# üîπ Combine both if needed\n",
        "combined_dataset = concatenate_datasets([existing_dataset, new_dataset])\n",
        "\n",
        "# Push to Hub\n",
        "combined_dataset.push_to_hub(\"AnjaliNV/Templete2\")\n"
      ],
      "metadata": {
        "id": "sJVCgiJql4qZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "MPFppF27TD2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "7cEfQeh5Vvxi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "mount_file_id": "https://github.com/AnjaliVaghjiani/Thesis/blob/main/WellBeing.ipynb",
      "authorship_tag": "ABX9TyOxBTelufKk+81wHhgup+gf"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}