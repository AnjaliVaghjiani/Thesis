{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Required libraries"
      ],
      "metadata": {
        "id": "2HXjH2crTOES"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJ2IZnY0spOf",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zBB_GqePIUt",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers accelerate bitsandbytes gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8Eu1zo5Q2Z54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain faiss-cpu sentence-transformers"
      ],
      "metadata": {
        "id": "PaVHh0jR-kvv",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3t4w4p6nK9CL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Rag Database"
      ],
      "metadata": {
        "id": "WvKXyudfNNA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "vectorstore = FAISS.load_local(\n",
        "    \"/content/drive/MyDrive/rag_index\",\n",
        "    embeddings=embedding_model,\n",
        "    allow_dangerous_deserialization=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "DganfMFKEXxW",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_full_rag_content(query, k=3):\n",
        "    \"\"\"Get complete content from RAG for specific queries\"\"\"\n",
        "\n",
        "    print(f\"üîç SEARCHING RAG FOR: '{query}'\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    try:\n",
        "        # Search your vectorstore\n",
        "        results = vectorstore.similarity_search(query, k=k)\n",
        "\n",
        "        if results:\n",
        "            print(f\"‚úÖ Found {len(results)} relevant documents\")\n",
        "\n",
        "            for i, result in enumerate(results):\n",
        "                print(f\"\\nüìÑ DOCUMENT {i+1}:\")\n",
        "                print(\"-\" * 40)\n",
        "                print(f\"FULL CONTENT ({len(result.page_content)} characters):\")\n",
        "                print(result.page_content)\n",
        "                print(\"-\" * 40)\n",
        "\n",
        "                # Check for specific keywords\n",
        "                keywords_found = []\n",
        "                search_terms = query.lower().split()\n",
        "\n",
        "                for term in search_terms:\n",
        "                    if term in result.page_content.lower():\n",
        "                        keywords_found.append(term)\n",
        "\n",
        "                print(f\"üìä Keywords found: {keywords_found}\")\n",
        "                print(f\"üìä Relevance: {len(keywords_found)}/{len(search_terms)} terms matched\")\n",
        "\n",
        "        else:\n",
        "            print(\"‚ùå No results found for this query\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Search error: {e}\")\n",
        "\n",
        "# Test with your specific example\n",
        "# print(\"üéØ TESTING SPECIFIC QUERY:\")\n",
        "# get_full_rag_content(\"zone minutes 42 year old female\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "# Test some other relevant queries\n",
        "test_queries = [\n",
        "    \"exercise recommendations 25 year old\",\n",
        "    # \"physical activity middle aged women\",\n",
        "    # \"cardio minutes weekly adults\",\n",
        "    # \"moderate intensity exercise adults\",\n",
        "    # \"150 minutes physical activity\"\n",
        "]\n",
        "\n",
        "for query in test_queries:\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    get_full_rag_content(query, k=2)  # Get top 2 results for each"
      ],
      "metadata": {
        "id": "_wXtPJAJq4le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data structure and Memory System"
      ],
      "metadata": {
        "id": "LV53MvRSxp2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime # Import datetime\n",
        "from typing import Dict, List\n",
        "import gradio as gr\n",
        "\n",
        "class SimpleDataManager:\n",
        "    \"\"\"Simple file-based storage for user data and recommendations\"\"\"\n",
        "\n",
        "    def __init__(self, data_dir=\"wellbeing_data\"):\n",
        "        self.data_dir = data_dir\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "        os.makedirs(f\"{data_dir}/users\", exist_ok=True)\n",
        "        os.makedirs(f\"{self.data_dir}/recommendations\", exist_ok=True) # Corrected path\n",
        "\n",
        "    def save_user_week(self, user_id: str, week_data: Dict):\n",
        "        \"\"\"Save weekly data for a user\"\"\"\n",
        "        user_file = f\"{self.data_dir}/users/{user_id}.json\"\n",
        "\n",
        "        try:\n",
        "            # Load existing data\n",
        "            if os.path.exists(user_file):\n",
        "                with open(user_file, 'r') as f:\n",
        "                    user_data = json.load(f)\n",
        "            else:\n",
        "                user_data = {\"user_id\": user_id, \"weeks\": []}\n",
        "\n",
        "            # Add new week\n",
        "            user_data[\"weeks\"].append(week_data)\n",
        "\n",
        "            # Keep only last 8 weeks\n",
        "            user_data[\"weeks\"] = user_data[\"weeks\"][-8:]\n",
        "\n",
        "            # Save\n",
        "            with open(user_file, 'w') as f:\n",
        "                json.dump(user_data, f, indent=2)\n",
        "\n",
        "            print(f\"‚úÖ Saved week data for user {user_id}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error saving user data: {str(e)}\")\n",
        "\n",
        "    def get_user_history(self, user_id: str) -> List[Dict]:\n",
        "        \"\"\"Get user's weekly history\"\"\"\n",
        "        user_file = f\"{self.data_dir}/users/{user_id}.json\"\n",
        "\n",
        "        try:\n",
        "            if os.path.exists(user_file):\n",
        "                with open(user_file, 'r') as f:\n",
        "                    user_data = json.load(f)\n",
        "                    history = user_data.get(\"weeks\", [])\n",
        "                    print(f\"üìä Retrieved {len(history)} weeks of history for {user_id}\")\n",
        "                    return history\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading user history: {str(e)}\")\n",
        "\n",
        "        return []\n",
        "\n",
        "    def save_recommendation(self, user_id: str, week_start: str, recommendation: str):\n",
        "        \"\"\"Save LLM recommendation\"\"\"\n",
        "        # Clean week_start for filename (remove invalid characters)\n",
        "        clean_week = week_start.replace(\"/\", \"-\").replace(\":\", \"-\")\n",
        "        rec_file = f\"{self.data_dir}/recommendations/{user_id}_{clean_week}.json\"\n",
        "\n",
        "        try:\n",
        "            rec_data = {\n",
        "                \"user_id\": user_id,\n",
        "                \"week_start\": week_start,\n",
        "                \"recommendation\": recommendation,\n",
        "                \"timestamp\": datetime.now().isoformat()\n",
        "            }\n",
        "\n",
        "            with open(rec_file, 'w') as f:\n",
        "                json.dump(rec_data, f, indent=2)\n",
        "\n",
        "            print(f\"‚úÖ Saved recommendation for user {user_id}, week {week_start}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error saving recommendation: {str(e)}\")\n",
        "\n",
        "    def get_last_recommendation(self, user_id: str) -> str:\n",
        "        \"\"\"Get user's last recommendation\"\"\"\n",
        "        rec_dir = f\"{self.data_dir}/recommendations\"\n",
        "\n",
        "        try:\n",
        "            # Check if recommendations directory exists\n",
        "            if not os.path.exists(rec_dir):\n",
        "                return \"\"\n",
        "\n",
        "            # Find latest recommendation file for this user\n",
        "            user_files = [f for f in os.listdir(rec_dir) if f.startswith(f\"{user_id}_\") and f.endswith('.json')]\n",
        "\n",
        "            if user_files:\n",
        "                # Sort by date and get latest\n",
        "                user_files.sort(reverse=True)\n",
        "                latest_file = f\"{rec_dir}/{user_files[0]}\"\n",
        "\n",
        "                with open(latest_file, 'r') as f:\n",
        "                    rec_data = json.load(f)\n",
        "                    recommendation = rec_data.get(\"recommendation\", \"\")\n",
        "                    print(f\"üìù Retrieved last recommendation for {user_id} ({len(recommendation)} chars)\")\n",
        "                    return recommendation\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading last recommendation: {str(e)}\")\n",
        "\n",
        "        return \"\"\n",
        "\n",
        "    def get_user_stats(self, user_id: str) -> Dict:\n",
        "        \"\"\"Get basic stats about user's data (bonus method)\"\"\"\n",
        "        history = self.get_user_history(user_id)\n",
        "\n",
        "        if not history:\n",
        "            return {\"total_weeks\": 0}\n",
        "\n",
        "        return {\n",
        "            \"total_weeks\": len(history),\n",
        "            \"first_week\": history[0].get(\"week_start\", \"Unknown\"),\n",
        "            \"latest_week\": history[-1].get(\"week_start\", \"Unknown\"),\n",
        "            \"avg_steps\": sum(week.get(\"total_steps\", 0) for week in history) // len(history),\n",
        "            \"avg_sleep\": sum(week.get(\"avg_sleep\", 0) for week in history) / len(history)\n",
        "        }"
      ],
      "metadata": {
        "id": "q9F2ra_wR8Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Well being LLM"
      ],
      "metadata": {
        "id": "qOWjDoksmrwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import re\n",
        "from typing import Dict, List\n",
        "\n",
        "\n",
        "class WellbeingLLM:\n",
        "    \"\"\"Improved LLM system for wellbeing recommendations with better prompt engineering\"\"\"\n",
        "\n",
        "    def __init__(self, base_model_id: str, adapter_path: str, vectorstore_path: str = None):\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "        self.device = None\n",
        "        self.vectorstore = None\n",
        "\n",
        "        # Load vectorstore if path provided\n",
        "        if vectorstore_path:\n",
        "            self.load_vectorstore(vectorstore_path)\n",
        "\n",
        "        self.load_model(base_model_id, adapter_path)\n",
        "\n",
        "    def load_vectorstore(self, vectorstore_path: str):\n",
        "        \"\"\"Load FAISS vectorstore for RAG\"\"\"\n",
        "        try:\n",
        "            from langchain.vectorstores import FAISS\n",
        "            from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "            print(\"üìö Loading knowledge base...\")\n",
        "            embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "            self.vectorstore = FAISS.load_local(\n",
        "                vectorstore_path,\n",
        "                embeddings=embedding_model,\n",
        "                allow_dangerous_deserialization=True\n",
        "            )\n",
        "            print(\"‚úÖ Knowledge base loaded\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Could not load vectorstore: {e}\")\n",
        "            self.vectorstore = None\n",
        "\n",
        "    def load_model(self, base_model_id: str, adapter_path: str = None):\n",
        "        \"\"\"Load the LLM model with better error handling\"\"\"\n",
        "        try:\n",
        "            print(\"ü§ñ Loading LLM...\")\n",
        "\n",
        "            from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "            from peft import PeftModel\n",
        "\n",
        "            # Clear GPU memory and check device\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "                print(f\"üîç GPU available: {torch.cuda.get_device_name()}\")\n",
        "            else:\n",
        "                print(\"üîç Using CPU\")\n",
        "\n",
        "            # Load tokenizer\n",
        "            print(\"üìù Loading tokenizer...\")\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
        "            if self.tokenizer.pad_token is None:\n",
        "                self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "            print(\"‚úÖ Tokenizer loaded\")\n",
        "\n",
        "            # Quantization config\n",
        "            bnb_config = BitsAndBytesConfig(\n",
        "                load_in_4bit=True,\n",
        "                bnb_4bit_quant_type=\"nf4\",\n",
        "                bnb_4bit_use_double_quant=True,\n",
        "                bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "            )\n",
        "            print(\"‚öôÔ∏è Quantization config ready\")\n",
        "\n",
        "            # Load base model\n",
        "            print(\"üß† Loading base model...\")\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                base_model_id,\n",
        "                device_map=\"auto\",\n",
        "                torch_dtype=torch.float16,  # Faster than float16\n",
        "                quantization_config=bnb_config,\n",
        "                trust_remote_code=True,\n",
        "                low_cpu_mem_usage=True,      # üöÄ NEW: Reduces CPU memory usage\n",
        "                use_cache=False,             # üöÄ NEW: Faster loading\n",
        "            )\n",
        "            print(\"‚úÖ Base model loaded\")\n",
        "\n",
        "            # Load fine-tuned adapter\n",
        "            # print(\"üéØ Loading fine-tuned adapter...\")\n",
        "            # self.model = PeftModel.from_pretrained(self.model, adapter_path)\n",
        "            self.model.eval()\n",
        "\n",
        "            # Store device for later use\n",
        "            self.device = next(self.model.parameters()).device\n",
        "            print(f\"‚úÖ LLM loaded successfully on {self.device}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå LLM loading failed: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            self.model = None\n",
        "            self.tokenizer = None\n",
        "            self.device = None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def generate_recommendation(self, current_week: Dict, user_history: List[Dict], last_recommendation: str) -> str:\n",
        "      \"\"\"Generate personalized recommendations with single template enforcement\"\"\"\n",
        "\n",
        "      if not self.model or not self.tokenizer:\n",
        "          print(\"‚ùå No model loaded\")\n",
        "          return \"Model not available. Please check model loading.\"\n",
        "\n",
        "      try:\n",
        "\n",
        "\n",
        "\n",
        "          # Use the single master template\n",
        "          query = self._build_master_template(current_week, user_history)\n",
        "\n",
        "\n",
        "          docs = self.vectorstore.similarity_search(query, k=3)\n",
        "\n",
        "\n",
        "          context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "          print(f\"the given prompt is {query}\")\n",
        "\n",
        "\n",
        "          prompt = (\n",
        "          f\"You are a helpful medical assistant. Use the following context to answer the question.\\n\\n\"\n",
        "          f\"Context:\\n{context}\\n\\n\"\n",
        "          f\"Question: {query}\\n\\nAnswer:\"\n",
        "      )\n",
        "          inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n",
        "          input_len = inputs[\"input_ids\"].shape[1]\n",
        "\n",
        "          print(f\"Model is on: {self.device}\")  # Should be 'cuda'\n",
        "\n",
        "\n",
        "          with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=700,\n",
        "                temperature=0.7,\n",
        "                top_p=0.95,\n",
        "                do_sample=True\n",
        "            )\n",
        "\n",
        "          generated_tokens = outputs[0][input_len:]\n",
        "          answer = self.tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "\n",
        "          return answer.strip()\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"‚ùå Generation error: {e}\")\n",
        "          return \"Failed to generate response.\"\n",
        "\n",
        "\n",
        "    def _build_master_template(self, current_week: Dict, user_history: List[Dict]) -> str:\n",
        "      \"\"\"Single master template with RAG-enhanced knowledge\"\"\"\n",
        "\n",
        "      # Extract user data\n",
        "      total_steps = current_week.get('total_steps', 0)\n",
        "      zone_minutes = current_week.get('zone_minutes', 0)\n",
        "      demographics = current_week.get('demographics', {})\n",
        "      age = demographics.get('age', 'unknown')\n",
        "      weight = demographics.get('weight', 'unknown')\n",
        "      height = demographics.get('height', 'unknown')\n",
        "      sex = demographics.get('sex', 'unknown')\n",
        "      avg_sleep = current_week.get('avg_sleep', 0)\n",
        "      diet_type = current_week.get('preferences', {}).get('diet_type', 'No Preference')\n",
        "      allergies = current_week.get('preferences', {}).get('allergies', [])\n",
        "      exercise_sessions = current_week.get('exercise_sessions', 0)\n",
        "      food_data = current_week.get('food_data', {})\n",
        "      dairy_liters = food_data.get('dairy_liters',0)\n",
        "      legumes = food_data.get('legumes_grams',0)\n",
        "      meat = food_data.get('meat_grams',0)\n",
        "      furits= food_data.get('fruits_grams',0)\n",
        "      vegtables = food_data.get('vegetables_grams',0)\n",
        "      grains = food_data.get('grains_grams',0)\n",
        "      nuts = food_data.get('nuts_seeds_grams',0)\n",
        "      water = food_data.get('water_liters',0)\n",
        "\n",
        "\n",
        "\n",
        "      # The master template with RAG integration\n",
        "      prompt = f\"\"\"\n",
        "A user is a {sex} aged {age} years, with a height of {height} cm and weight of {weight} kg. They walk about {total_steps:,} steps weekly, average {zone_minutes} zone minutes, and do {exercise_sessions} exercise sessions per week. They sleep around {avg_sleep:.1f} hours each night. Their diet preference is {diet_type}, and they are allergic to {', '.join(allergies) if allergies else 'none'}\n",
        "and their this weekly food consumption is dairy {dairy_liters} liter, legumes {legumes} grams, meat {meat} grams, fruits {furits} grams, vegtables = {vegtables},\n",
        " grains {grains} grams, nuts {nuts} grams and water {water} liter .\n",
        "\n",
        "Based on this profile and the expert knowledge below, provide health and wellness recommendations in the format outlined.\n",
        "---\n",
        "\n",
        "**1) Food Recommendation**\n",
        "- Overall Assessment: [...]\n",
        "- Areas of Improvements: [...]\n",
        "- Suggested Meals: [...]\n",
        "\n",
        "**2) Physical Activity**\n",
        "- Activity Assessment: [...]\n",
        "- Zone Minutes and intensity Feedback\n",
        "- Strength/Cardio Tips: [suggest also exercise for strength and cardio]\n",
        "- Weekly Goals: [...]\n",
        "\n",
        "**3) Sleep & Well-being**\n",
        "- Sleep Review: [...]\n",
        "- Suggestions: [...]\n",
        "\n",
        "**4) Weekly Summary**\n",
        "- Summary: [...]\n",
        "- Goals: [...]\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "      return prompt\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Svqnq5QaerSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Well being system"
      ],
      "metadata": {
        "id": "ZJ-reNgcm3Id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WellbeingSystem:\n",
        "    \"\"\"Main system that combines data management and LLM\"\"\"\n",
        "\n",
        "    def __init__(self, base_model_id: str, adapter_path: str, vectorstore_path: str = None):\n",
        "        self.data_manager = SimpleDataManager()\n",
        "        self.llm = WellbeingLLM(base_model_id, adapter_path, vectorstore_path) # Pass vectorstore_path to LLM\n",
        "        print(\"üéØ WellbeingSystem initialized\")\n",
        "\n",
        "    def analyze_and_recommend(self, user_id: str, week_data: Dict) -> str:\n",
        "        \"\"\"Main function: analyze weekly data and generate recommendations\"\"\"\n",
        "\n",
        "        print(f\"üìä Analyzing data for user: {user_id}\")\n",
        "\n",
        "        try:\n",
        "            # Get user history and last recommendation\n",
        "            user_history = self.data_manager.get_user_history(user_id)\n",
        "            last_recommendation = self.data_manager.get_last_recommendation(user_id)\n",
        "\n",
        "            print(f\"üìà Found {len(user_history)} weeks of history\")\n",
        "            if last_recommendation:\n",
        "                print(f\"üìù Previous recommendation found ({len(last_recommendation)} chars)\")\n",
        "\n",
        "            # Process current week data\n",
        "            processed_week = self._process_week_data(week_data)\n",
        "\n",
        "            # Show what data is being sent to LLM\n",
        "            print(f\"üìä Processed data: {processed_week['total_steps']:,} steps, {processed_week['zone_minutes']} zone mins, {processed_week['avg_sleep']:.1f}h sleep\")\n",
        "\n",
        "            # Generate recommendation using LLM\n",
        "            recommendation = self.llm.generate_recommendation(\n",
        "                processed_week, user_history, last_recommendation\n",
        "            )\n",
        "\n",
        "            # Save data (with error handling)\n",
        "            try:\n",
        "                self.data_manager.save_user_week(user_id, processed_week)\n",
        "                self.data_manager.save_recommendation(user_id, processed_week['week_start'], recommendation)\n",
        "                print(f\"üíæ Data saved successfully\")\n",
        "            except Exception as save_error:\n",
        "                print(f\"‚ö†Ô∏è Warning: Could not save data: {save_error}\")\n",
        "                # Continue anyway - return the recommendation even if saving fails\n",
        "\n",
        "            print(f\"‚úÖ Generated recommendation for {user_id} ({len(recommendation)} chars)\")\n",
        "            return recommendation\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error in analyze_and_recommend: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return f\"Analysis failed: {str(e)}. Please check your input data.\"\n",
        "\n",
        "    def _process_week_data(self, week_data: Dict) -> Dict:\n",
        "        \"\"\"Process and standardize weekly data with better validation\"\"\"\n",
        "\n",
        "        try:\n",
        "            # Parse sleep and mood data with validation\n",
        "            sleep_hours = week_data.get('sleep_hours', [])\n",
        "            mood_scores = week_data.get('mood_scores', [])\n",
        "\n",
        "            # Handle string input (comma-separated values)\n",
        "            if isinstance(sleep_hours, str):\n",
        "                try:\n",
        "                    sleep_hours = [float(x.strip()) for x in sleep_hours.split(',') if x.strip()]\n",
        "                except ValueError:\n",
        "                    print(\"‚ö†Ô∏è Invalid sleep hours format, using default\")\n",
        "                    sleep_hours = []\n",
        "\n",
        "            if isinstance(mood_scores, str):\n",
        "                try:\n",
        "                    mood_scores = [float(x.strip()) for x in mood_scores.split(',') if x.strip()]\n",
        "                except ValueError:\n",
        "                    print(\"‚ö†Ô∏è Invalid mood scores format, using default\")\n",
        "                    mood_scores = []\n",
        "\n",
        "            # Calculate averages with validation\n",
        "            avg_sleep = sum(sleep_hours) / len(sleep_hours) if sleep_hours else 0\n",
        "            avg_mood = sum(mood_scores) / len(mood_scores) if mood_scores else 0\n",
        "\n",
        "            # üöÄ ADD DEBUG:\n",
        "            print(f\"üîç DEBUG - Sleep calculation: {sleep_hours} ‚Üí avg: {avg_sleep}\")\n",
        "            print(f\"üîç DEBUG - Mood calculation: {mood_scores} ‚Üí avg: {avg_mood}\")\n",
        "\n",
        "            # Enhanced food data processing\n",
        "            food_data = self._process_food_data(week_data)\n",
        "\n",
        "            processed_data = {\n",
        "                'week_start': week_data.get('week_start', datetime.now().strftime('%Y-%m-%d')),\n",
        "                'total_steps': max(0, int(week_data.get('total_steps', 0))), # Ensure int and non-negative\n",
        "                'zone_minutes': max(0, int(week_data.get('zone_minutes', 0))), # Ensure int and non-negative\n",
        "                'exercise_sessions': max(0, int(week_data.get('exercise_sessions', 0))), # Ensure int and non-negative\n",
        "                'avg_sleep': round(avg_sleep, 1),\n",
        "                'avg_mood': round(avg_mood, 1),\n",
        "                'food_data': food_data,\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'demographics': week_data.get('demographics', {})\n",
        "            }\n",
        "\n",
        "            # Include preferences and targets if present in the input week_data\n",
        "            if 'preferences' in week_data:\n",
        "                processed_data['preferences'] = week_data['preferences']\n",
        "            if 'targets' in week_data:\n",
        "                processed_data['targets'] = week_data['targets']\n",
        "\n",
        "\n",
        "            return processed_data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing week data: {str(e)}\")\n",
        "            # Return empty or default data structure on error\n",
        "            return {\n",
        "                 'week_start': week_data.get('week_start', datetime.now().strftime('%Y-%m-%d')),\n",
        "                 'total_steps': 0,\n",
        "                 'zone_minutes': 0,\n",
        "                 'exercise_sessions': 0,\n",
        "                 'avg_sleep': 0.0,\n",
        "                 'avg_mood': 0.0,\n",
        "                 'food_data': {},\n",
        "                 'timestamp': datetime.now().isoformat(),\n",
        "                 'processing_error': str(e)\n",
        "            }\n",
        "\n",
        "\n",
        "    def _process_food_data(self, week_data: Dict) -> Dict:\n",
        "        \"\"\"Process food data handling both old and new formats\"\"\"\n",
        "\n",
        "        food_data = {}\n",
        "\n",
        "        # Check for new format first (with units)\n",
        "        unit_fields = ['dairy_liters', 'water_liters', 'legumes_grams', 'meat_grams',\n",
        "                      'fruits_grams', 'vegetables_grams', 'grains_grams', 'nuts_seeds_grams']\n",
        "\n",
        "        has_unit_format = any(field in week_data for field in unit_fields)\n",
        "\n",
        "        if has_unit_format:\n",
        "            print(\"üìä Using new format (with units)\")\n",
        "            # New format with units\n",
        "            for field in unit_fields:\n",
        "                value = week_data.get(field, 0)\n",
        "                try:\n",
        "                    food_data[field] = max(0, float(value))  # Ensure non-negative\n",
        "                except (ValueError, TypeError):\n",
        "                    food_data[field] = 0\n",
        "                    print(f\"‚ö†Ô∏è Invalid {field} value, using 0\")\n",
        "        else:\n",
        "            print(\"üìä Using old format (servings)\")\n",
        "            # Old format (for backward compatibility)\n",
        "            old_fields = ['dairy', 'legumes', 'meat', 'fruits', 'vegetables', 'grains', 'nuts_seeds', 'water_glasses']\n",
        "            for field in old_fields:\n",
        "                if field in week_data:\n",
        "                    try:\n",
        "                        food_data[field] = max(0, float(week_data[field]))\n",
        "                    except (ValueError, TypeError):\n",
        "                        food_data[field] = 0\n",
        "\n",
        "        return food_data\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b75h28FTlLM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Well being app"
      ],
      "metadata": {
        "id": "94F3XlNDm99_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "from typing import Dict, List\n",
        "\n",
        "class WellbeingApp:\n",
        "    \"\"\"Complete Gradio interface with targets, history, and preferences\"\"\"\n",
        "\n",
        "    def __init__(self, base_model_id: str, adapter_path: str):\n",
        "      print(\"üöÄ Initializing Complete WellbeingApp...\")\n",
        "      self.wellbeing_system = WellbeingSystem(\n",
        "          base_model_id,\n",
        "          adapter_path,\n",
        "          vectorstore_path=\"/content/drive/MyDrive/rag_index\"\n",
        "      )\n",
        "\n",
        "      # Default targets (same as before)\n",
        "      self.default_targets = {\n",
        "          'weekly_steps': 70000,\n",
        "          'weekly_zone_minutes': 150,\n",
        "          'daily_sleep_hours': 8.0,\n",
        "          'weekly_water_liters': 14.0,\n",
        "          'weekly_fruits_grams': 2100,\n",
        "          'weekly_vegetables_grams': 3500,\n",
        "          'weekly_exercise_sessions': 4\n",
        "      }\n",
        "\n",
        "    def create_wellbeing_app(self):\n",
        "        \"\"\"Create comprehensive Gradio interface with tabs\"\"\"\n",
        "\n",
        "        with gr.Blocks(title=\"üè• Complete Wellbeing LLM\", theme=gr.themes.Soft()) as demo:\n",
        "\n",
        "            gr.Markdown(\"# üè• Complete AI Wellbeing System\")\n",
        "            gr.Markdown(\"### Personalized health recommendations with custom targets and progress tracking\")\n",
        "\n",
        "            # Create tabs for different sections\n",
        "            with gr.Tabs():\n",
        "\n",
        "                # TAB 1: MAIN ANALYSIS\n",
        "                with gr.TabItem(\"ü§ñ Get Recommendations\", elem_id=\"main-tab\"):\n",
        "                    self._create_main_analysis_tab()\n",
        "\n",
        "                # TAB 2: TARGETS CUSTOMIZATION\n",
        "                with gr.TabItem(\"üéØ Customize Targets\", elem_id=\"targets-tab\"):\n",
        "                    self._create_targets_tab()\n",
        "\n",
        "                # TAB 3: HISTORY REVIEW\n",
        "                with gr.TabItem(\"üìà Progress History\", elem_id=\"history-tab\"):\n",
        "                    self._create_history_tab()\n",
        "\n",
        "                # TAB 4: SYSTEM INFO\n",
        "                # with gr.TabItem(\"‚ÑπÔ∏è System Info\", elem_id=\"info-tab\"):\n",
        "                #     self._create_info_tab()\n",
        "\n",
        "        return demo\n",
        "\n",
        "    def _create_main_analysis_tab(self):\n",
        "      \"\"\"Create the main analysis tab with fixed component handling\"\"\"\n",
        "\n",
        "      with gr.Row():\n",
        "          with gr.Column():\n",
        "\n",
        "              gr.Markdown(\"### ü§ñ AI Enhancement Options\")\n",
        "              # User Info Section\n",
        "              gr.Markdown(\"### üë§ User Information\")\n",
        "              user_id = gr.Textbox(label=\"üë§ User ID\", value=\"user_001\", info=\"Unique identifier for tracking your progress\")\n",
        "              week_start = gr.Textbox(label=\"üìÖ Week Start Date\", value=\"2024-01-15\", info=\"Format: YYYY-MM-DD\")\n",
        "\n",
        "              # Personal Details - FIXED: These were not being collected properly\n",
        "              sex = gr.Dropdown(\n",
        "                  label=\"‚ößÔ∏è Sex\",\n",
        "                  choices=[\"Male\", \"Female\", \"Other\", \"Prefer not to say\"],\n",
        "                  value=\"Male\",\n",
        "                  info=\"Biological sex for health calculations\"\n",
        "              )\n",
        "\n",
        "              age = gr.Number(\n",
        "                  label=\"üéÇ Age\",\n",
        "                  value=25,\n",
        "                  minimum=13,\n",
        "                  maximum=120,\n",
        "                  step=1,\n",
        "                  info=\"Age in years\"\n",
        "              )\n",
        "\n",
        "              weight = gr.Number(\n",
        "                  label=\"‚öñÔ∏è Weight (kg)\",\n",
        "                  value=70.0,\n",
        "                  minimum=30.0,\n",
        "                  maximum=300.0,\n",
        "                  step=0.1,\n",
        "                  info=\"Current weight in kilograms\"\n",
        "              )\n",
        "\n",
        "              height = gr.Number(\n",
        "                  label=\"üìè Height (cm)\",\n",
        "                  value=175.0,\n",
        "                  minimum=100.0,\n",
        "                  maximum=250.0,\n",
        "                  step=0.1,\n",
        "                  info=\"Height in centimeters\"\n",
        "              )\n",
        "\n",
        "              # Preferences Section\n",
        "              gr.Markdown(\"### üçΩÔ∏è Meal Preferences & Dietary Restrictions\")\n",
        "              with gr.Row():\n",
        "                  diet_type = gr.Dropdown(\n",
        "                      label=\"ü•ó Diet Type\",\n",
        "                      choices=[\n",
        "                          \"No Preference\", \"Vegetarian\", \"Vegan\", \"Pescatarian\",\n",
        "                          \"Keto\", \"Paleo\", \"Mediterranean\", \"Low Carb\", \"Gluten Free\", \"Dairy Free\"\n",
        "                      ],\n",
        "                      value=\"No Preference\",\n",
        "                      info=\"Select your primary dietary preference\"\n",
        "                  )\n",
        "\n",
        "              allergies = gr.CheckboxGroup(\n",
        "                  label=\"‚ö†Ô∏è Food Allergies & Intolerances\",\n",
        "                  choices=[\n",
        "                      \"Nuts (Tree nuts)\", \"Peanuts\", \"Shellfish\", \"Fish\",\n",
        "                      \"Milk/Dairy\", \"Eggs\", \"Soy\", \"Wheat/Gluten\",\n",
        "                      \"Sesame\", \"Lactose Intolerant\", \"Other\"\n",
        "                  ],\n",
        "                  info=\"‚ö†Ô∏è IMPORTANT: Select all allergies and intolerances\"\n",
        "              )\n",
        "\n",
        "              other_allergies = gr.Textbox(\n",
        "                  label=\"üö® Other Allergies/Restrictions\",\n",
        "                  placeholder=\"e.g., tomatoes, specific medications, religious restrictions...\",\n",
        "                  info=\"Specify any other dietary restrictions or allergies\"\n",
        "              )\n",
        "\n",
        "              # Activity Section\n",
        "              gr.Markdown(\"### üèÉ‚Äç‚ôÇÔ∏è Physical Activity\")\n",
        "              total_steps = gr.Number(label=\"Total Steps (Week)\", value=65000, info=\"Your current target will be shown\")\n",
        "              zone_minutes = gr.Number(label=\"Zone Minutes (Week)\", value=120, info=\"Your current target will be shown\")\n",
        "              exercise_sessions = gr.Number(label=\"Exercise Sessions\", value=3, info=\"Your current target will be shown\")\n",
        "\n",
        "              # Sleep & Mood Section\n",
        "              gr.Markdown(\"### üò¥ Sleep & Mood\")\n",
        "              sleep_hours = gr.Textbox(\n",
        "                  label=\"Sleep Hours (7 days)\",\n",
        "                  value=\"7.5,6.8,8.2,7.0,6.5,8.5,7.8\",\n",
        "                  info=\"Enter daily sleep hours separated by commas\"\n",
        "              )\n",
        "              mood_scores = gr.Textbox(\n",
        "                  label=\"Mood Scores (7 days)\",\n",
        "                  value=\"4,3.5,5,3,4,2.5,5\",\n",
        "                  info=\"Rate your daily mood from 1-5, separated by commas\"\n",
        "              )\n",
        "\n",
        "              # Food Section\n",
        "              gr.Markdown(\"### üçé Weekly Nutrition Intake\")\n",
        "              gr.Markdown(\"*Enter your total consumption for the entire week*\")\n",
        "\n",
        "              with gr.Row():\n",
        "                  dairy = gr.Number(label=\"ü•õ Dairy (liters)\", value=3.5, info=\"Milk, yogurt, cheese\")\n",
        "                  water_liters = gr.Number(label=\"üíß Water (liters)\", value=48, info=\"Your current target will be shown\")\n",
        "\n",
        "              with gr.Row():\n",
        "                  fruits = gr.Number(label=\"üçé Fruits (grams)\", value=2100, info=\"Your current target will be shown\")\n",
        "                  vegetables = gr.Number(label=\"ü•¨ Vegetables (grams)\", value=3500, info=\"Your current target will be shown\")\n",
        "\n",
        "              with gr.Row():\n",
        "                  legumes = gr.Number(label=\"ü´ò Legumes (grams)\", value=350, info=\"Beans, lentils, peas\")\n",
        "                  nuts_seeds = gr.Number(label=\"ü•ú Nuts/Seeds (grams)\", value=210, info=\"Almonds, walnuts, chia seeds\")\n",
        "\n",
        "              with gr.Row():\n",
        "                  meat = gr.Number(label=\"üçó Meat (grams)\", value=700, info=\"Chicken, beef, fish\")\n",
        "                  grains = gr.Number(label=\"üåæ Grains (grams)\", value=2800, info=\"Rice, bread, pasta, oats\")\n",
        "\n",
        "              # Action buttons\n",
        "              with gr.Row():\n",
        "                  analyze_btn = gr.Button(\"ü§ñ Get AI Recommendations\", variant=\"primary\", size=\"lg\")\n",
        "                  load_targets_btn = gr.Button(\"üìä Load My Targets\", variant=\"secondary\")\n",
        "\n",
        "          with gr.Column():\n",
        "              main_output = gr.Markdown(\"\"\"\n",
        "  Suggestions\n",
        "  \"\"\")\n",
        "\n",
        "      # FIXED: Store components with correct order including demographics\n",
        "      self.main_components = {\n",
        "          'user_id': user_id,\n",
        "          'week_start': week_start,\n",
        "          'sex': sex,           # ADDED: Missing demographic fields\n",
        "          'age': age,           # ADDED\n",
        "          'weight': weight,     # ADDED\n",
        "          'height': height,     # ADDED\n",
        "          'total_steps': total_steps,\n",
        "          'zone_minutes': zone_minutes,\n",
        "          'exercise_sessions': exercise_sessions,\n",
        "          'sleep_hours': sleep_hours,\n",
        "          'mood_scores': mood_scores,\n",
        "          'dairy_liters': dairy,\n",
        "          'legumes_grams': legumes,\n",
        "          'meat_grams': meat,\n",
        "          'fruits_grams': fruits,\n",
        "          'vegetables_grams': vegetables,\n",
        "          'grains_grams': grains,\n",
        "          'nuts_seeds_grams': nuts_seeds,\n",
        "          'water_liters': water_liters,\n",
        "          'diet_type': diet_type,\n",
        "          'allergies': allergies,\n",
        "          'other_allergies': other_allergies,\n",
        "          'output': main_output\n",
        "      }\n",
        "\n",
        "      # FIXED: Connect button with correct inputs order\n",
        "      analyze_btn.click(\n",
        "          fn=self.analyze_wellbeing_with_preferences,\n",
        "          inputs=[\n",
        "              user_id, week_start, sex, age, weight, height,  # Demographics in correct order\n",
        "              total_steps, zone_minutes, exercise_sessions,\n",
        "              sleep_hours, mood_scores, dairy, legumes, meat,\n",
        "              fruits, vegetables, grains, nuts_seeds, water_liters,\n",
        "              diet_type, allergies, other_allergies\n",
        "          ],\n",
        "          outputs=[main_output]\n",
        "      )\n",
        "\n",
        "      load_targets_btn.click(\n",
        "          fn=self.load_user_targets,\n",
        "          inputs=[user_id],\n",
        "          outputs=[main_output]\n",
        "      )\n",
        "\n",
        "    def analyze_wellbeing_with_preferences(self, user_id, week_start, sex, age, weight, height,\n",
        "                                     total_steps, zone_minutes, exercise_sessions,\n",
        "                                     sleep_hours, mood_scores, dairy_liters, legumes_grams, meat_grams,\n",
        "                                     fruits_grams, vegetables_grams, grains_grams, nuts_seeds_grams, water_liters,\n",
        "                                     diet_type, allergies, other_allergies):\n",
        "      \"\"\"Enhanced analysis with agent support, custom targets, and user demographics\"\"\"\n",
        "\n",
        "      try:\n",
        "          # Input validation\n",
        "          if not user_id or not user_id.strip():\n",
        "              return \"‚ùå Error: Please enter a valid User ID\"\n",
        "\n",
        "          if not week_start:\n",
        "              return \"‚ùå Error: Please enter a week start date\"\n",
        "\n",
        "          # Validate demographic data\n",
        "          if age is not None and (age < 13 or age > 120):\n",
        "              return \"‚ùå Error: Please enter a valid age (13-120 years)\"\n",
        "\n",
        "          if weight is not None and (weight < 30 or weight > 300):\n",
        "              return \"‚ùå Error: Please enter a valid weight (30-300 kg)\"\n",
        "\n",
        "          if height is not None and (height < 100 or height > 250):\n",
        "              return \"‚ùå Error: Please enter a valid height (100-250 cm)\"\n",
        "\n",
        "          # Load user's custom targets\n",
        "          user_targets = self.get_user_targets(user_id.strip())\n",
        "\n",
        "          # Calculate BMI if weight and height are provided\n",
        "          bmi = None\n",
        "          if weight and height:\n",
        "              height_m = height / 100  # Convert cm to meters\n",
        "              bmi = round(weight / (height_m ** 2), 1)\n",
        "\n",
        "          # Prepare enhanced data with demographics\n",
        "          week_data = {\n",
        "              'user_id': user_id.strip(),\n",
        "              'week_start': week_start,\n",
        "              'demographics': {\n",
        "                  'sex': sex,\n",
        "                  'age': int(age) if age else None,\n",
        "                  'weight': float(weight) if weight else None,\n",
        "                  'height': float(height) if height else None,\n",
        "                  'bmi': bmi\n",
        "              },\n",
        "              'total_steps': max(0, int(total_steps)) if total_steps else 0,\n",
        "              'zone_minutes': max(0, int(zone_minutes)) if zone_minutes else 0,\n",
        "              'exercise_sessions': max(0, int(exercise_sessions)) if exercise_sessions else 0,\n",
        "              'sleep_hours': sleep_hours,\n",
        "              'mood_scores': mood_scores,\n",
        "              'dairy_liters': max(0, float(dairy_liters)) if dairy_liters else 0,\n",
        "              'legumes_grams': max(0, float(legumes_grams)) if legumes_grams else 0,\n",
        "              'meat_grams': max(0, float(meat_grams)) if meat_grams else 0,\n",
        "              'fruits_grams': max(0, float(fruits_grams)) if fruits_grams else 0,\n",
        "              'vegetables_grams': max(0, float(vegetables_grams)) if vegetables_grams else 0,\n",
        "              'grains_grams': max(0, float(grains_grams)) if grains_grams else 0,\n",
        "              'nuts_seeds_grams': max(0, float(nuts_seeds_grams)) if nuts_seeds_grams else 0,\n",
        "              'water_liters': max(0, float(water_liters)) if water_liters else 0,\n",
        "              'preferences': {\n",
        "                  'diet_type': diet_type,\n",
        "                  'allergies': allergies if allergies else [],\n",
        "                  'other_allergies': other_allergies.strip() if other_allergies else \"\"\n",
        "              },\n",
        "              'targets': user_targets\n",
        "          }\n",
        "\n",
        "          recommendation = self.wellbeing_system.analyze_and_recommend(user_id.strip(), week_data)\n",
        "\n",
        "          # Enhanced output with custom targets and demographics\n",
        "          output = self._format_analysis_output_with_targets(week_data, recommendation, user_targets)\n",
        "\n",
        "          return output\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"‚ùå Analysis error: {str(e)}\")\n",
        "          import traceback\n",
        "          traceback.print_exc()\n",
        "          return f\"‚ùå Error: {str(e)}\\n\\nPlease check your input format and try again.\"\n",
        "\n",
        "\n",
        "    def _create_targets_tab(self):\n",
        "        \"\"\"Create the targets customization tab\"\"\"\n",
        "\n",
        "        gr.Markdown(\"## üéØ Customize Your Personal Health Targets\")\n",
        "        gr.Markdown(\"### Set personalized goals based on your fitness level, health conditions, and personal objectives\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### üë§ User Selection\")\n",
        "                target_user_id = gr.Textbox(label=\"üë§ User ID\", value=\"user_001\", info=\"Enter the user ID to customize targets for\")\n",
        "\n",
        "                gr.Markdown(\"### üèÉ‚Äç‚ôÇÔ∏è Activity Targets\")\n",
        "                target_weekly_steps = gr.Number(\n",
        "                    label=\"Weekly Steps Target\",\n",
        "                    value=70000,\n",
        "                    info=\"Default: 70,000 (10,000 daily). Adjust based on fitness level.\"\n",
        "                )\n",
        "                target_zone_minutes = gr.Number(\n",
        "                    label=\"Weekly Zone Minutes Target\",\n",
        "                    value=150,\n",
        "                    info=\"Default: 150 minutes. WHO recommends 150+ minutes moderate exercise.\"\n",
        "                )\n",
        "                target_exercise_sessions = gr.Number(\n",
        "                    label=\"Weekly Exercise Sessions Target\",\n",
        "                    value=4,\n",
        "                    info=\"Default: 4 sessions. Include both cardio and strength training.\"\n",
        "                )\n",
        "\n",
        "                gr.Markdown(\"### üò¥ Sleep & Recovery Targets\")\n",
        "                target_daily_sleep = gr.Number(\n",
        "                    label=\"Daily Sleep Hours Target\",\n",
        "                    value=8.0,\n",
        "                    info=\"Default: 8 hours. Range: 7-9 hours for most adults.\"\n",
        "                )\n",
        "\n",
        "                with gr.Row():\n",
        "                    save_targets_btn = gr.Button(\"üíæ Save My Targets\", variant=\"primary\", size=\"lg\")\n",
        "                    load_current_targets_btn = gr.Button(\"üìä Load Current Targets\", variant=\"secondary\")\n",
        "                    reset_defaults_btn = gr.Button(\"üîÑ Reset to Defaults\", variant=\"secondary\")\n",
        "\n",
        "\n",
        "        # Store target components\n",
        "        self.target_components = {\n",
        "            'user_id': target_user_id,\n",
        "            'weekly_steps': target_weekly_steps,\n",
        "            'zone_minutes': target_zone_minutes,\n",
        "            'exercise_sessions': target_exercise_sessions,\n",
        "            'daily_sleep': target_daily_sleep,\n",
        "        }\n",
        "\n",
        "        # Connect buttons\n",
        "        save_targets_btn.click(\n",
        "            fn=self.save_user_targets,\n",
        "            inputs=list(self.target_components.values())[:-1],\n",
        "            # outputs=[targets_output]\n",
        "        )\n",
        "\n",
        "        load_current_targets_btn.click(\n",
        "            fn=self.load_user_targets_display,\n",
        "            inputs=[target_user_id],\n",
        "            outputs=list(self.target_components.values()) # Update all target number boxes and output\n",
        "        )\n",
        "\n",
        "        reset_defaults_btn.click(\n",
        "            fn=self.reset_to_defaults,\n",
        "            outputs=list(self.target_components.values())\n",
        "        )\n",
        "\n",
        "\n",
        "    def _create_history_tab(self):\n",
        "        \"\"\"Create the history review tab\"\"\"\n",
        "\n",
        "        gr.Markdown(\"## üìà Progress History & Analytics\")\n",
        "        gr.Markdown(\"### Track your health journey and see improvements over time\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### üë§ User Selection\")\n",
        "                history_user_id = gr.Textbox(label=\"üë§ User ID\", value=\"user_001\", info=\"Enter user ID to view history\")\n",
        "\n",
        "                gr.Markdown(\"### üìä Analysis Options\")\n",
        "                analysis_type = gr.Radio(\n",
        "                    label=\"üìà View Type\",\n",
        "                    choices=[\n",
        "                        \"üìä Complete Progress Summary\",\n",
        "                        \"üìà Weekly Trends Analysis\",\n",
        "                        \"üéØ Target Achievement Report\",\n",
        "                        \"üìã Raw Data Export\",\n",
        "                        \"üèÜ Achievement Milestones\"\n",
        "                    ],\n",
        "                    value=\"üìä Complete Progress Summary\",\n",
        "                    info=\"Choose what type of analysis you want to see\"\n",
        "                )\n",
        "\n",
        "                weeks_to_show = gr.Slider(\n",
        "                    label=\"üìÖ Weeks to Include\",\n",
        "                    minimum=1,\n",
        "                    maximum=12,\n",
        "                    value=4,\n",
        "                    step=1,\n",
        "                    info=\"How many recent weeks to analyze\"\n",
        "                )\n",
        "\n",
        "                with gr.Row():\n",
        "                    view_history_btn = gr.Button(\"üìä View Progress\", variant=\"primary\", size=\"lg\")\n",
        "                    export_data_btn = gr.Button(\"üíæ Export Data\", variant=\"secondary\")\n",
        "                    delete_history_btn = gr.Button(\"üóëÔ∏è Clear History\", variant=\"stop\")\n",
        "\n",
        "\n",
        "\n",
        "        # Store history components\n",
        "        self.history_components = {\n",
        "            'user_id': history_user_id,\n",
        "            'analysis_type': analysis_type,\n",
        "            'weeks_to_show': weeks_to_show,\n",
        "            # 'output': history_output\n",
        "        }\n",
        "\n",
        "    def _format_preferences_display(self, preferences: dict) -> str:\n",
        "        \"\"\"Format preferences for nice display\"\"\"\n",
        "\n",
        "        lines = [\"### üçΩÔ∏è Your Dietary Profile:\"]\n",
        "\n",
        "        # Diet type\n",
        "        if preferences.get('diet_type', 'No Preference') != \"No Preference\":\n",
        "            lines.append(f\"- **Diet:** {preferences['diet_type']}\")\n",
        "\n",
        "        # Allergies (most important!)\n",
        "        if preferences.get('allergies'):\n",
        "            allergy_list = \", \".join(preferences['allergies'])\n",
        "            lines.append(f\"- **‚ö†Ô∏è ALLERGIES:** {allergy_list}\")\n",
        "\n",
        "        if preferences.get('other_allergies'):\n",
        "            lines.append(f\"- **‚ö†Ô∏è OTHER RESTRICTIONS:** {preferences['other_allergies']}\")\n",
        "\n",
        "        if len(lines) == 1:  # Only the header\n",
        "            lines.append(\"- No specific dietary preferences set\")\n",
        "\n",
        "        return \"\\n\".join(lines)\n",
        "\n",
        "\n",
        "\n",
        "    def _format_analysis_output_with_targets(self, week_data, recommendation, user_targets):\n",
        "      \"\"\"Format analysis output including custom targets\"\"\"\n",
        "\n",
        "      daily_steps = week_data['total_steps'] / 7\n",
        "      daily_water = week_data['water_liters'] / 7\n",
        "\n",
        "      # Safely get avg_sleep and avg_mood with defaults\n",
        "      avg_sleep = week_data.get('avg_sleep', 0)\n",
        "      avg_mood = week_data.get('avg_mood', 0)\n",
        "\n",
        "      # Compare against custom targets\n",
        "      targets_comparison = f\"\"\"\n",
        "  ### üéØ Target Performance:\n",
        "  - **Steps:** {week_data['total_steps']:,} / {user_targets['weekly_steps']:,} {'‚úÖ' if week_data['total_steps'] >= user_targets['weekly_steps'] else '‚ö†Ô∏è'} ({((week_data['total_steps'] / user_targets['weekly_steps']) * 100):.0f}%)\n",
        "  - **Zone Minutes:** {week_data['zone_minutes']} / {user_targets['weekly_zone_minutes']} {'‚úÖ' if week_data['zone_minutes'] >= user_targets['weekly_zone_minutes'] else '‚ö†Ô∏è'} ({((week_data['zone_minutes'] / user_targets['weekly_zone_minutes']) * 100):.0f}%)\n",
        "  - **Sleep:** {avg_sleep:.1f}h / {user_targets['daily_sleep_hours']}h {'‚úÖ' if avg_sleep >= user_targets['daily_sleep_hours'] else '‚ö†Ô∏è'}\n",
        "  - **Water:** {week_data['water_liters']:.1f}L / {user_targets['weekly_water_liters']}L {'‚úÖ' if week_data['water_liters'] >= user_targets['weekly_water_liters'] else '‚ö†Ô∏è'}\n",
        "\"\"\"\n",
        "\n",
        "      preferences_display = self._format_preferences_display(week_data['preferences'])\n",
        "\n",
        "      return f\"\"\"# üè• Personalized Wellbeing Analysis & Recommendations\n",
        "\n",
        "  ## üë§ User: {week_data['user_id']} | üìÖ Week: {week_data['week_start']}\n",
        "\n",
        "  {preferences_display}\n",
        "\n",
        "  {targets_comparison}\n",
        "\n",
        "  ### üìä Your Weekly Data Summary:\n",
        "  **üèÉ‚Äç‚ôÇÔ∏è Activity:**\n",
        "  - **Steps:** {week_data['total_steps']:,} ({daily_steps:.0f}/day)\n",
        "  - **Zone Minutes:** {week_data['zone_minutes']}\n",
        "  - **Exercise Sessions:** {week_data['exercise_sessions']}\n",
        "\n",
        "  **üò¥ Sleep & Mood:**\n",
        "  - **Sleep:** {week_data['sleep_hours']} hours daily\n",
        "  - **Mood:** {week_data['mood_scores']}/10 daily scores\n",
        "\n",
        "  **üçé Nutrition:**\n",
        "  - ü•õ **Dairy:** {week_data['dairy_liters']:.1f}L | üíß **Water:** {week_data['water_liters']:.1f}L ({daily_water:.1f}L/day)\n",
        "  - üçé **Fruits:** {week_data['fruits_grams']:.0f}g | ü•¨ **Vegetables:** {week_data['vegetables_grams']:.0f}g\n",
        "  - ü´ò **Legumes:** {week_data['legumes_grams']:.0f}g | üçó **Meat:** {week_data['meat_grams']:.0f}g\n",
        "  - üåæ **Grains:** {week_data['grains_grams']:.0f}g | ü•ú **Nuts/Seeds:** {week_data['nuts_seeds_grams']:.0f}g\n",
        "\n",
        "  ---\n",
        "\n",
        "  ## ü§ñ AI Recommendations\n",
        "  *Personalized based on your data, preferences, allergies, and custom targets*\n",
        "\n",
        "  {recommendation}\n",
        "  \"\"\"\n",
        "\n",
        "    def load_user_targets(self, user_id):\n",
        "        \"\"\"Load user targets and format for display in main tab\"\"\"\n",
        "        try:\n",
        "            if not user_id or not user_id.strip():\n",
        "                return \"‚ùå Please enter a valid User ID\"\n",
        "\n",
        "            targets = self.get_user_targets(user_id.strip())\n",
        "\n",
        "            return f\"\"\"# üìä Your Current Targets Loaded\n",
        "\n",
        "## üéØ Targets for {user_id}:\n",
        "\n",
        "### üèÉ‚Äç‚ôÇÔ∏è Activity Targets:\n",
        "- **Weekly Steps:** {targets['weekly_steps']:,}\n",
        "- **Zone Minutes:** {targets['weekly_zone_minutes']}\n",
        "- **Exercise Sessions:** {targets['weekly_exercise_sessions']}\n",
        "\n",
        "### üò¥ Recovery Target:\n",
        "- **Daily Sleep:** {targets['daily_sleep_hours']} hours\n",
        "\n",
        "### üçé Nutrition Targets:\n",
        "- **Weekly Water:** {targets['weekly_water_liters']} liters\n",
        "- **Weekly Fruits:** {targets['weekly_fruits_grams']:,} grams\n",
        "- **Weekly Vegetables:** {targets['weekly_vegetables_grams']:,} grams\n",
        "\n",
        "*These targets will be used to evaluate your progress when you get AI recommendations.*\n",
        "\n",
        "**üí° Tip:** Go to the 'Customize Targets' tab to modify these values if needed.\n",
        "\"\"\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"‚ùå Error loading targets: {str(e)}\"\n",
        "\n",
        "    def save_user_targets(self, user_id, weekly_steps, zone_minutes, exercise_sessions,\n",
        "                          daily_sleep, weekly_water):\n",
        "        \"\"\"Saves user's custom targets to a file\"\"\"\n",
        "        if not user_id or not user_id.strip():\n",
        "            return \"‚ùå Error: Please enter a valid User ID to save targets.\"\n",
        "\n",
        "        targets_file = f\"{self.wellbeing_system.data_manager.data_dir}/targets_{user_id.strip()}.json\"\n",
        "\n",
        "        try:\n",
        "            targets_data = {\n",
        "                'weekly_steps': int(weekly_steps) if weekly_steps else self.default_targets['weekly_steps'],\n",
        "                'weekly_zone_minutes': int(zone_minutes) if zone_minutes else self.default_targets['weekly_zone_minutes'],\n",
        "                'weekly_exercise_sessions': int(exercise_sessions) if exercise_sessions else self.default_targets['weekly_exercise_sessions'],\n",
        "                'daily_sleep_hours': float(daily_sleep) if daily_sleep else self.default_targets['daily_sleep_hours'],\n",
        "                'weekly_water_liters': float(weekly_water) if weekly_water else self.default_targets['weekly_water_liters'],\n",
        "              }\n",
        "\n",
        "            with open(targets_file, 'w') as f:\n",
        "                json.dump(targets_data, f, indent=2)\n",
        "\n",
        "            return f\"‚úÖ Targets saved successfully for user '{user_id.strip()}'.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"‚ùå Error saving targets: {str(e)}\"\n",
        "\n",
        "    def get_user_targets(self, user_id: str) -> Dict:\n",
        "        \"\"\"Loads user's custom targets, or returns defaults\"\"\"\n",
        "        targets_file = f\"{self.wellbeing_system.data_manager.data_dir}/targets_{user_id.strip()}.json\"\n",
        "\n",
        "        if os.path.exists(targets_file):\n",
        "            try:\n",
        "                with open(targets_file, 'r') as f:\n",
        "                    targets = json.load(f)\n",
        "                    # Ensure all keys from default are present (for backward compatibility)\n",
        "                    full_targets = self.default_targets.copy()\n",
        "                    full_targets.update(targets)\n",
        "                    return full_targets\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Warning: Could not load targets for user '{user_id.strip()}': {str(e)}. Using defaults.\")\n",
        "                return self.default_targets\n",
        "        else:\n",
        "            return self.default_targets\n",
        "\n",
        "    def load_user_targets_display(self, user_id):\n",
        "        \"\"\"Loads user targets and formats for display in the targets tab\"\"\"\n",
        "        if not user_id or not user_id.strip():\n",
        "             return \"‚ùå Error: Please enter a valid User ID to load targets.\", *[gr.Number(value=self.default_targets[key]) for key in self.default_targets] # Return defaults to update UI\n",
        "\n",
        "        targets = self.get_user_targets(user_id.strip())\n",
        "\n",
        "        output_message = f\"‚úÖ Loaded targets for user '{user_id.strip()}'.\"\n",
        "\n",
        "        # Return the message and the target values to update the Gradio Number components\n",
        "        return (\n",
        "            output_message,\n",
        "            targets.get('weekly_steps', self.default_targets['weekly_steps']),\n",
        "            targets.get('weekly_zone_minutes', self.default_targets['weekly_zone_minutes']),\n",
        "            targets.get('weekly_exercise_sessions', self.default_targets['weekly_exercise_sessions']),\n",
        "            targets.get('daily_sleep_hours', self.default_targets['daily_sleep_hours']),\n",
        "            targets.get('weekly_water_liters', self.default_targets['weekly_water_liters']),\n",
        "            )\n",
        "\n",
        "    def reset_to_defaults(self):\n",
        "        \"\"\"Resets the target input fields to default values\"\"\"\n",
        "        return (\n",
        "            \"üéØ Resetting targets to defaults.\",\n",
        "            self.default_targets['weekly_steps'],\n",
        "            self.default_targets['weekly_zone_minutes'],\n",
        "            self.default_targets['weekly_exercise_sessions'],\n",
        "            self.default_targets['daily_sleep_hours'],\n",
        "            self.default_targets['weekly_water_liters'],\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "yMJif8UIexLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main execution"
      ],
      "metadata": {
        "id": "czFxU-C-nVSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment to run:\n",
        "app = WellbeingApp(base_model_id=\"ContactDoctor/Bio-Medical-Llama-3-8B\", adapter_path=\"AnjaliNV/WellBeing_LLM\")\n",
        "demo = app.create_wellbeing_app()\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "PK-nsLf7nPwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tuning"
      ],
      "metadata": {
        "id": "Vil6ywcR26VX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel\n",
        "import torch # Import torch to check for CUDA\n",
        "\n",
        "# Load your dataset from JSONL\n",
        "data_path = \"/content/diet_finetune_examples.jsonl\"\n",
        "data = []\n",
        "with open(data_path, \"r\") as f:\n",
        "    for line in f:\n",
        "        item = json.loads(line)\n",
        "        user_msg = next(msg[\"content\"] for msg in item[\"messages\"] if msg[\"role\"] == \"user\")\n",
        "        assistant_msg = next(msg[\"content\"] for msg in item[\"messages\"] if msg[\"role\"] == \"assistant\")\n",
        "        prompt = f\"<|user|>\\n{user_msg}\\n<|assistant|>\\n{assistant_msg}\"\n",
        "        data.append({\"text\": prompt})\n",
        "\n",
        "# Convert to Hugging Face Dataset\n",
        "dataset = Dataset.from_list(data)\n",
        "dataset = dataset.train_test_split(test_size=0.1)\n",
        "\n",
        "# Load tokenizer and base model\n",
        "model_id = \"ContactDoctor/Bio-Medical-Llama-3-8B\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# --- Use BitsAndBytesConfig for 4-bit loading ---\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config, # Use quantization_config instead of load_in_8bit\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16, # Use bfloat16 for compute dtype\n",
        "    low_cpu_mem_usage=True,\n",
        ")\n",
        "\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "# Apply LoRA PEFT configuration\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize, batched=True)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./diet-finetuned-model\",\n",
        "    per_device_train_batch_size=1,  # Keep reduced batch size\n",
        "    per_device_eval_batch_size=1,   # Keep reduced batch size\n",
        "    num_train_epochs=3,\n",
        "    logging_dir=\"./logs\",\n",
        "    save_total_limit=2,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=False, # Set to False when using bfloat16 or 4-bit\n",
        "    bf16=True, # Enable bfloat16 if supported by GPU\n",
        "    save_strategy=\"epoch\",\n",
        "    report_to=\"none\",\n",
        "    gradient_checkpointing=True, # Keep gradient checkpointing enabled\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "# Start fine-tuning\n",
        "trainer.train()\n",
        "\n",
        "# Save final LoRA adapter\n",
        "model.save_pretrained(\"AnjaliNV/WellBeing_LLM\")\n",
        "tokenizer.save_pretrained(\"AnjaliNV/WellBeing_LLM\")"
      ],
      "metadata": {
        "id": "-bShTepJxc4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adapter_path = \"AnjaliNV/WellBeing_LLM\"\n",
        "model.push_to_hub(adapter_path, use_auth_token=True)\n",
        "tokenizer.push_to_hub(adapter_path, use_auth_token=True)"
      ],
      "metadata": {
        "id": "CvR6chF1650I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#test"
      ],
      "metadata": {
        "id": "iFZ_NxymQ614"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.schema import Document\n",
        "\n",
        "# === Load FAISS vector store ===\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "vectorstore = FAISS.load_local(\n",
        "    \"/content/drive/MyDrive/rag_index\",\n",
        "    embeddings=embedding_model,\n",
        "    allow_dangerous_deserialization=True\n",
        ")\n",
        "\n",
        "# === Load LLaMA 3 model with LoRA adapter ===\n",
        "base_model_id = \"ContactDoctor/Bio-Medical-Llama-3-8B\"\n",
        "adapter_path = \"AnjaliNV/WellBeing_LLM\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_id,\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "model = PeftModel.from_pretrained(base_model, adapter_path)\n",
        "model.eval()\n",
        "\n",
        "# === Define RAG-based response generation ===\n",
        "def generate_with_rag(query, temperature=0.7, max_tokens=256, k=3):\n",
        "    # Step 1: Retrieve relevant docs\n",
        "    docs = vectorstore.similarity_search(query, k=k)\n",
        "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "    # Step 2: Construct the prompt\n",
        "    prompt = (\n",
        "        f\"You are a helpful medical assistant. Use the following context to answer the question.\\n\\n\"\n",
        "        f\"Context:\\n{context}\\n\\n\"\n",
        "        f\"Question: {query}\\n\\nAnswer:\"\n",
        "    )\n",
        "\n",
        "    # Step 3: Tokenize and generate\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    input_len = inputs[\"input_ids\"].shape[1]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=0.95,\n",
        "            do_sample=True\n",
        "        )\n",
        "\n",
        "    # Step 4: Decode only the generated answer\n",
        "    generated_tokens = outputs[0][input_len:]\n",
        "    answer = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "\n",
        "    return answer.strip()\n",
        "\n",
        "# === Gradio UI ===\n",
        "iface = gr.Interface(\n",
        "    fn=generate_with_rag,\n",
        "    inputs=[\n",
        "        gr.Textbox(lines=4, label=\"Enter your medical question\"),\n",
        "        gr.Slider(0.1, 1.0, value=0.7, label=\"Temperature\"),\n",
        "        gr.Slider(64, 1024, step=64, value=256, label=\"Max Tokens\"),\n",
        "        gr.Slider(1, 5, step=1, value=3, label=\"Top K Documents\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Model Response\"),\n",
        "    title=\"RAG-Powered BioMedical LLaMA 3 Assistant\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True, debug=True)\n"
      ],
      "metadata": {
        "id": "qNR9jkRNQ8Jz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/AnjaliVaghjiani/Thesis/blob/main/WellBeing.ipynb",
      "authorship_tag": "ABX9TyP4LvapkE7hz4c++oq3TLwa"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}