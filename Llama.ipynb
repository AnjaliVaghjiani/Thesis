{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1204,
     "status": "ok",
     "timestamp": 1749647813130,
     "user": {
      "displayName": "Anjali Vaghjiani",
      "userId": "03778564321957104488"
     },
     "user_tz": -120
    },
    "id": "QiGgE1g-HVOl",
    "outputId": "8dd08a6b-f55a-47ed-c3ef-6fabe53eb0f4"
   },
   "outputs": [],
   "source": [
    "# Replace <your_token>, <your_username>, and <repo_name>\n",
    "!git clone https://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@github.com/AnjaliVaghjiani/Thesis.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 138,
     "status": "ok",
     "timestamp": 1749648277728,
     "user": {
      "displayName": "Anjali Vaghjiani",
      "userId": "03778564321957104488"
     },
     "user_tz": -120
    },
    "id": "B4W1rpTfJ8k7",
    "outputId": "47f3bb35-0c9a-476c-9ab5-30fbd05ecd5a"
   },
   "outputs": [],
   "source": [
    "!cp \"/content/drive/MyDrive/Colab Notebooks/Llama.ipynb\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7267,
     "status": "ok",
     "timestamp": 1749647418199,
     "user": {
      "displayName": "Anjali Vaghjiani",
      "userId": "03778564321957104488"
     },
     "user_tz": -120
    },
    "id": "MpYvg_ZSHJ45",
    "outputId": "5614694d-0ce8-4642-f702-509863c8a164"
   },
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrYRwDFP3VnL"
   },
   "source": [
    "# MedALpaca LLM\n",
    "\n",
    "- required GPU RAM > 15GB so\n",
    "- Device used L4 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13142,
     "status": "ok",
     "timestamp": 1748944104212,
     "user": {
      "displayName": "Anjali Vaghjiani",
      "userId": "03778564321957104488"
     },
     "user_tz": -120
    },
    "id": "GJ2IZnY0spOf",
    "outputId": "41259a15-4690-4de2-9a97-e9da956dcff1"
   },
   "outputs": [],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81663,
     "status": "ok",
     "timestamp": 1748962689089,
     "user": {
      "displayName": "Anjali Vaghjiani",
      "userId": "03778564321957104488"
     },
     "user_tz": -120
    },
    "id": "eHa4OWkuvz3S",
    "outputId": "da8d6933-5734-4f2c-fe6b-b139d7d8d8a4"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers accelerate bitsandbytes gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 781,
     "referenced_widgets": [
      "0ccd5e12a2e84a13b407037e9a8be83c",
      "03cb8a47a28f452aabe74932a8e1403a",
      "843106ffeefb4387ad652f5b6c1fbff9",
      "7119e374579d4e62825157d504101f59",
      "7ef6fe6c84e74ac898c2485631703e66",
      "abc8edf57e11475d96b8d623b3dd6986",
      "966e5d55b704413797f0493b3a13cf6e",
      "55aa690d3ac84e64aa01ad625134ab80",
      "6f2ed4ad6edc473d9d7bde7ae34821dd",
      "14f69e458540401e9517159382ffe947",
      "244c73111bb147eb974b9732c4038d02"
     ]
    },
    "id": "zNVvxTdtlN3a",
    "outputId": "d35307c7-f08b-4c8a-8b89-d6dd10ab95b1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import gradio as gr\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_id = \"medalpaca/medalpaca-7b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.eval()\n",
    "\n",
    "# Chat function with history\n",
    "def chat_interface(message, history):\n",
    "    # Reconstruct prompt with history\n",
    "    prompt = \"\"\n",
    "    for user_msg, bot_msg in history:\n",
    "        prompt += f\"### Instruction:\\n{user_msg}\\n\\n### Response:\\n{bot_msg}\\n\\n\"\n",
    "    prompt += f\"### Instruction:\\n{message}\\n\\n### Response:\\n\"\n",
    "\n",
    "    # Tokenize and generate\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=512,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.1,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Only return new response (strip old prompt)\n",
    "    if \"### Response:\" in response:\n",
    "        response = response.split(\"### Response:\")[-1].strip()\n",
    "\n",
    "    return response\n",
    "\n",
    "# Launch Gradio Chat Interface\n",
    "gr.ChatInterface(\n",
    "    fn=chat_interface,\n",
    "    title=\"ðŸ§  MedAlpaca 7B - Medical Chatbot\",\n",
    "    description=\"Ask medical or wellness-related questions. Powered by medAlpaca 7B.\",\n",
    ").launch(debug=True, share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQs-1g9pO2vc"
   },
   "source": [
    "# ContactDoctor Bio Medical LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 173680,
     "status": "ok",
     "timestamp": 1749644800362,
     "user": {
      "displayName": "Anjali Vaghjiani",
      "userId": "03778564321957104488"
     },
     "user_tz": -120
    },
    "id": "3zBB_GqePIUt",
    "outputId": "eb62fb6d-86a5-4db4-e7f3-aa65160e4231"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers accelerate bitsandbytes gradio flash_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "628ca67211f34522b67cc99a662ef3e7",
      "b7742008b6354041a1177140fd6d3eea",
      "13404ade48894f019bf91f5e75629d41",
      "4a80c237051a4e2983e03ed3246c6f44",
      "cddf629769094d598dfecd0f6cdebfe0",
      "ca026f15b3264ffda7f443e8697e7fae",
      "5f06680503104c92991b75073e74f269",
      "2a48e37d32384b998c8ba0787f877c77",
      "3cb62c7ef9f44cbfa73924f33457e4e9",
      "66b0fb57a09f4e4283b4884569e86b20",
      "787f03e317ba4fbca8051dce3ed35df1",
      "4750240df19f48299faba4bdc60f9097",
      "93687238c8864445bc7e2935f395dc84",
      "1745417c2dba46e4a1816e1f3951bad6",
      "2243a746d43d4bfcb508fb40269671a6",
      "bd52b6be85d646669167b024d5771153",
      "ba6221bae740499090437053b7fcbfa9",
      "13cc971da3154d4c9f70a9e32cac0560",
      "3fb7b729d2a0427cabbd48c6cce7e4e3",
      "112a03a558ef414596d45dea178ff9de",
      "3299241e3d0545f88ee127a906ef7932",
      "715a92e467f743c1b5f2d9a29fb0c2fb",
      "78ccbdaa291d4732ba3f0c9d2f669ad5",
      "3d052ece26a146009f71173f04db851a",
      "05646d1389fa4718a4aad95699069ad8",
      "ba26a1d34ba44b08af75b62821e80840",
      "e6958ef2f5094d37b9b207ea53e72517",
      "8daaec65b605401baa484f603330ad61",
      "6d5f6f093423498caf5ad35dc1f81ff7",
      "d16a2519f3244a50a72019981bac7e43",
      "ece6b111b2554537a64bb9e93839d368",
      "f6becbd15d4c4890ade3a579295a4527",
      "9de761081bc9428682b6a9a2858c8fda",
      "d660cb6d80d04eaf838ab1be4942a1f1",
      "88cea90648e949789f9d8da15e0523bc",
      "9ee2b711a14b477c9abf342a784c77f2",
      "ebc7ea00888d42aa9eaf37358614b7c4",
      "11682070c3f64b4e906110e86590b7bb",
      "049c7a4bf16c4d5f8bbeb00fd2d71ab4",
      "4243dfb04ce1431c9775a849e69078bb",
      "4d107bda42154c749cb0f52b998b56b9",
      "f61400467d8143dba55a8e473903b226",
      "c31e97108725461e898292c0aefbac1a",
      "0c33d5c6714d49e087afc79469b49132",
      "31c72b3c41ed4fe2947efd0bf479eb04",
      "ef5af7a1fa544be0b10c0509253f0c5a",
      "60086f10259c4728bd3055c16eb87136",
      "782936e5ce864ee09a1ae6434e5192c5",
      "700b65317c94469784edc9ddab54a86a",
      "56b30598567d4ddea03a9e9739c00d63",
      "78adb5c37f50427c847d46910e1a89bb",
      "1203684a46494b55a8dab09979dc2f8b",
      "57c163b989e34af3a7b0828fe82e4944",
      "4b516d1155f440cb87af6322382e14ee",
      "7bb05990e46e47afaaee59f9ec4d84a4",
      "ee34714d5efb4a999125e6f19bc66aa2",
      "e3dd307d40dd4a6bb68e4cdceab58c35",
      "879a7cd39feb4dc388ed169f08bba865",
      "82a04f69952b422797c0b1b4fca88e83",
      "d4e49612e73e4780bf4bfdd9c1be386e",
      "2a8bfca55b2d4128ae5a1557a11037e2",
      "68e85dfeb9534ef890d788df78e00e8a",
      "39540299481d4a70bcc5d7698cb94baf",
      "9f88a3597ec744c18a6e6370e6729e15",
      "2271ded6cf2143918e06584632f80332",
      "9588fc6c6930425db03d2d5a252b2b98",
      "b4791a3c441e456f8bc7e421426bf9a1",
      "1e225077f2db4a348fd1a0d5ac6d74e5",
      "39ee210fa16e4ad9bb5476b76b6cf424",
      "ba82104fd9dd44d7ba5a802ae89158ef",
      "36bb8c11e6134c71bc396340bd6d75d2",
      "fbabee10556446eeb87975c848253b5d",
      "d518bccaa37e4f9fbe648fa7c738c95e",
      "9b9127d1c1974904b2363f65f2202e50",
      "5b38936711614d249cf28fc1f2cb1de9",
      "1b6a34884f9449e6872b1f518c9d6907",
      "f800a8894dfc4294a14238c132196a9c",
      "f49e5477a0774e178c687ed706b5b4b7",
      "bcd0a07a930943aaa5649be8488c54d0",
      "8b7872a27ccc4e8f8aad07c9c7c5e93c",
      "8334f2fba67249babf2ec8444fefd1e4",
      "77606ffc075a4ec98a28e93483332c66",
      "20ae25154fe74cecae93c741066209ac",
      "82604bfb4b19493dbe0d5988a55cc75a",
      "926c751397a64d1db47da39c432923f1",
      "8af319576ec74a16b6117bc7a2723100",
      "7a0d206bc7a2471ab365b3366a1619d3",
      "8d4645b0ee2941e493dbc6acaaea000a",
      "f08d2fd6ef5f42faa63f63605edf630a",
      "2cfb8ea2a830457dbe3008b6c2d436b8",
      "69659ba6c475472f9fcc77d549e57119",
      "a699a96c5e8a4a35a6c764c27a7cde5b",
      "44ebdd8f2bb54001bf993d961277c815",
      "d46e770d11c7492ab9b056d67593c231",
      "400d4b56d262471fb33ad310985d24fa",
      "c1a668c25bf747e9b67c48a845a9b0d5",
      "135a5e77316741c7950129d2704ad45f",
      "e26c767dcdbf41acaadb047e10acdcb0",
      "e4f1a18a09cd40f6985f292081158011"
     ]
    },
    "executionInfo": {
     "elapsed": 2588918,
     "status": "ok",
     "timestamp": 1749647389272,
     "user": {
      "displayName": "Anjali Vaghjiani",
      "userId": "03778564321957104488"
     },
     "user_tz": -120
    },
    "id": "vFQNul7TO1AW",
    "outputId": "47ab75a6-2b9a-432d-adfc-ac881d3d7721"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "from transformers import AutoModel, AutoTokenizer, BitsAndBytesConfig\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "# ---- Model Setup ----\n",
    "model_id = \"ContactDoctor/Bio-Medical-Llama-3-8B\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig( load_in_4bit=True, bnb_4bit_quant_type=\"nf4\",\n",
    "                                bnb_4bit_use_double_quant=True,\n",
    "                                bnb_4bit_compute_dtype=torch.float16, )\n",
    "\n",
    "print(\"ðŸ”„ Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "\n",
    "print(\"ðŸ”„ Loading model...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# ---- Chat Function ----\n",
    "def chat_only_interface(message, history):\n",
    "\n",
    "#the tempelet to receive the prompts\n",
    "    prompt_template = f\"\"\"\n",
    "  You are a wellbeing adviser. Respond to the user's condition using the following format:\n",
    "\n",
    "  1. Food Recommendation:\n",
    "  2. Physical Exercise:\n",
    "  3. Social Wellbeing Recommendation:\n",
    "  4. Overall Suggestion:\n",
    "\n",
    "  User Input: \"{message}\"\n",
    "  \"\"\"\n",
    "    inputs = tokenizer(prompt_template, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.95,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.1,\n",
    "    )\n",
    "\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Trim to just the model's response part\n",
    "    generated_text = response.split(\"User Input:\")[1] if \"User Input:\" in response else response\n",
    "\n",
    "    with open(\"chat_history.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"User: {message}\\n\")\n",
    "        f.write(f\"Model: {response}\\n\\n\")\n",
    "\n",
    "    return generated_text.strip()\n",
    "\n",
    "# ---- Chat Interface ----\n",
    "gr.ChatInterface(\n",
    "    fn=chat_only_interface,\n",
    "    title=\"ðŸ§  Bio-Medical LLaMA 3 Chat\",\n",
    "    description=\"Ask wellness or medical-related questions.\",\n",
    ").queue().launch(debug=True, share=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UoOA1Lq6E7tM"
   },
   "source": [
    "# Medgemma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8090,
     "status": "ok",
     "timestamp": 1749040297341,
     "user": {
      "displayName": "Anjali Vaghjiani",
      "userId": "03778564321957104488"
     },
     "user_tz": -120
    },
    "id": "BwqhvruEFe4U",
    "outputId": "1ccc58f7-86be-43f0-ddd7-121490d51129"
   },
   "outputs": [],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10029,
     "status": "ok",
     "timestamp": 1749040308659,
     "user": {
      "displayName": "Anjali Vaghjiani",
      "userId": "03778564321957104488"
     },
     "user_tz": -120
    },
    "id": "0tqih35eFbDP",
    "outputId": "4ee99f62-9b96-4c69-cdf7-62ac4da397be"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers accelerate gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 914,
     "referenced_widgets": [
      "34144e3e0bee4511949750e1fb4a6842",
      "7693c1fec642445e8e6879cf55dfc51c",
      "5ab33a1a402f4a99bd594f17baae9292",
      "2e1c006e1d5b4b38863a69f662e717ee",
      "0d19b8bcb5fe4c69ad253d495ae68520",
      "a6f36aff14484c72a2220c6db53fad72",
      "4966871e16c040c5b17e5db0b66d6536",
      "d40036e2e83d43bfb50f5e7081a86c8c",
      "71e09b3a422e474891f80ee8546b1dbd",
      "9551d520f4204c39ad0ea5b5f4d053b1",
      "0195827ba9c4473d8f0a7dc473e5d381",
      "4a20f5612fbc4af2989a90193fbb1eae",
      "6a5e4a8bf1ff41fdb191ba8e6729a68e",
      "99a1aa6ba5734f41b770e46c7c20a29a",
      "f8881c452a7f4e14968361011c2fe270",
      "6a060a4f87d044cba45b72cf887c2421",
      "e9c23cab178e4720a8d6153400b6479b",
      "e3e8e8f144ea4881997ec92b265d143d",
      "4efae039cb3f45608013b4b4942cd4d9",
      "a11a97a6773849df915d5af38d43ff0a",
      "bd98f8dd02f2454fbd7c82efd0f48fd3",
      "f406d2cab7ba490382fd938a61e623b2",
      "2100d56dd866404dbf0e3db18a67bc22",
      "de5f6489292a45cd85dc1d8eddb7415d",
      "9004e02dce064e1c975b7df6a8ff2f2f",
      "67ced8eff04b44b2bf361a90525b8af4",
      "94791c4dcbc04e8788451e562873d9ba",
      "653fa9b2332b41fd804db30235a8ad57",
      "0502112fadbf44da949bbe2edf2f1ae8",
      "051cad1761bb4a1ea4ad9a10b43113a9",
      "133329c1a63949398896205d7d2b3993",
      "655fdedd8e12499d9cba5791a3121f30",
      "049375a3a7bd4821845ba5024a615638",
      "9d2b2e7ff3fe46e7b38ccc2c862b9df7",
      "d2bf5268e8f04780a2b9a61310e78d09",
      "633e26ebf9c34a0eac36287d6fb44d50",
      "23cb7ba5f7e249f395c076c8bb2d4897",
      "6c1c9789494e419db590f853a68c3d01",
      "dafbd4a03aac444e9395e31387e3bf12",
      "2dd26644fa3c4129b2fdb987435b53e3",
      "1618331151ba46b2835678bb543d5c9a",
      "f575c5c4165246ffbbbd53b86a73883f",
      "b980c4752c7f4a7bacd2f81b04cbc5b7",
      "b7b08a00ea5e4bd5a67b48517703fbd2",
      "ee77ebc236a54690912b385f1ebc1f24",
      "f30a23ec7f834235a585a59b2f9da1e5",
      "d94f27b9cba8424ebc843204db12d8e7",
      "73cf24a6b3db47539a2ec22edb90d194",
      "ae6be229c1694133bc23cd3f04b24f65",
      "f1e27bc848244f47b7961dbddee6b575",
      "47ffceee7e834847b417dc4177e01061",
      "7d7b0c6f4aa142dd8f9eb8a888db7f6e",
      "942a824fcb8e477c9c36bc4e0d92aa65",
      "781a49c986814aa7ba3965f15eadb80a",
      "aa5744aa5a9f4da7a47608fa82b5d1be",
      "1e12ca36b00c4f67a785633133fa6f19",
      "71ad4733ac1f48a8bab336ff7f8f87e3",
      "ab0e31b832194a6ca1507903993f0455",
      "1547c18276e04c7ab2cd54917cf5ebe8",
      "d36ee16e6600468da1678f0c5e7a3243",
      "bec7edf902954cc69119f38dcd563b7c",
      "f30f51864431406a9e14d98cabb5e37e",
      "a6965e3b49024118b1095c43ed92ada9",
      "072c451d637b4f9c832b2afcec4166bc",
      "16d84b7f90384b4a97153fef8c9a6dcc",
      "011b7ebaad974f88b475b55d5e201df2",
      "da1051674bf4447283ac8388cebe4e9f",
      "640e331c73a04c949c637934c07560e6",
      "b414cf34b80f4fdba94665eb5d4438de",
      "f726cf27fd5d4125a756004d214ddc33",
      "880566181e4546eca5c8c3170f269c95",
      "10fc8e9966cd4899a313b1915a4c6071",
      "b8a7d6344ffe4bbd99dffb278ddb4091",
      "65d6c94f9fd647b591ca2c7820f582d0",
      "03f2c06d3c1745c6b086b90a85d9de4b",
      "e328d473845d4b06adb491cc3afaaf7b",
      "6489ad7c3ef74096965753358f3f8a58",
      "9c2cafbc36674f788f26c54ae520e11d",
      "7ff02ca491264562807eac9209cab6ae",
      "a9d29ab98c38449f8b23c26f2a9394fa",
      "a5c5f54f46f54961b89f096a4b90f369",
      "ba602ef1f4f84887b5a88c4da000de09",
      "ee1fa41f10e14b578238ff5ec53276f1",
      "91a24c87b9314cf8982be7f3ab67bbb5",
      "acd74e455fad4345b46b2bf037f9a1ba",
      "1acaab4aff9d4a73b42f19726a5798ab",
      "f02d4c0e72a3495e86bde6bec6235a65",
      "74523876e65740aeb1ee4ba763f257b6",
      "6ca9839a983f4ec9ba50188729568640",
      "1ce770de9ad24c99895cd3ca4814cb48",
      "e86134fa33e542a4a0e6fb1f31529cdc",
      "c2979ebc7bdf433085491c4f92ef3201",
      "b56cf13344434764867ec56ef02c7d3e",
      "a55ad6dfa78a45bcb11d81ee3eed29a3",
      "e409330a44b34ca8b0453f42f802b175",
      "173d87ec4063496da33b8e947afda52f",
      "fbf93532f8914d54a4c8912825084c9e",
      "7e8b25788d4d4c34bd4b555e586516b1",
      "3324eb51f6ba4521aebbfe649cb71cda",
      "85295ea376f44d13ac8c0de4b2084b7a",
      "df6963618f1f47588e898dec0b9355df",
      "3705f672af584126950c5de6661dc11c",
      "7334482d99114f8c85280ebe7c1b0ef8",
      "7d3ab8c8c91e480185e787f10f829ff1",
      "8631dfcaaae54bc5b3e536125b6fd2d2",
      "2fb6178402f949308847af2ca7781616",
      "b314af30bbb249a9a9ebb6ed57065e52",
      "55715bee682142c3ad0c7074b4b22534",
      "7b7a50ca15394eed94106b251fee04d8",
      "ca330e89cb904ba7b2762ff4e628ac20",
      "379203037ffb48eeb11d8f9834074de6",
      "50dc171991bf4b44a106ab7905e5d918",
      "cefa3579a5c94310bd6c8ed1e2453075",
      "629e04d9c70a4537b9631666a296df61",
      "82d1da63ce1a4d02a9d8128408e2f4f4",
      "8d95e9cc813c4ac69fcff45c7e87a083",
      "ce1b5584f8d146919d9474fa742be55a",
      "6091da511b84483dbba749a77536052d",
      "9cd65c747c924ebdae63b81ae7321b93",
      "0cea37f9dd2243108ed356ccbebb69f4",
      "86ec6d5e28954a068533878729fdd405",
      "057ec05d8d0d4468b4dcebed10a4271d",
      "d9813dde35dd4d97b8456ff198580655",
      "828a128c65914e66ab6c490b34a9a6e1",
      "aa69c5ad5d694968a1b4b916da5488cc",
      "9696936758c04d9194eac9e7c3d62c5f",
      "c3de336f4b4a4b85a5ee602a19873e7d",
      "63b6b81a2a244742a608957919a071f5",
      "66a972e35dd847a4ac8b678cacbedde6",
      "032629e0b16f46e493a2b4d7f7a13d35",
      "d283ad15e70e4e0a9475101698c60734",
      "4218c25646f948ad9cf4cd1c4864627e",
      "4a70ec2bf199454a805812399d5fc91e",
      "370b472762c144559ab6b975f307b3a3",
      "8beef5a5be5f4c35b413a9fc990c7e4d",
      "e5289b2e31c745828cad0510ccd25905",
      "8ac6a2a5a5b9438f839c92b5fd1aba1f",
      "b04a55e1875b4bf38ef2bcdab77bfe5e",
      "7c3fafe3d72f4978bebbff9b4215b015",
      "abf59df9ef1844c19fe8e4177fcf90b9",
      "3527c42356eb4153b4158e0f265bd8e9",
      "63cd6c7261ae494c8410a007130cdc6d",
      "1e11f6c826714f05856ec5d067aa0052",
      "1626cde5322347cd981fb94bb5e70035",
      "bb62793f5d8d4389a98ce175b7a0ea9e",
      "9c291b689d8544e39cc1aa14d3f18c21",
      "3073f843580f470f82868c333bafa6c4",
      "3715428505134a658de78d2f56796b76",
      "f456a239fced4ccea7232ef72a78129c",
      "0724e44f1a6f4ea2af3a2dd656b3d105",
      "5df08020f2724cc3be31f865b4a914e3",
      "4bfa8270b26a4d01b53503567279bdb6",
      "675ccde995e3448c85b832647d29def8",
      "e9ce31ea2e754829aed79c6a6a29a216",
      "62af31642529475489ce890604cb2482",
      "59afa44a966646f29407f993330d2ba6",
      "6226fc8542dd45948dd41a4162391624",
      "eb6955cbb3e04e5e842a5fc9ee9e5788",
      "b8a2bc80cd6f4f4b8f20c67a10f7040b",
      "a5949e431420484fb2f6e591aff13348",
      "497cdbb59dd047f584c9e107657d225c",
      "f376078b6731487480e5df908e9ba61f",
      "7757da78378d432c84a444009f1b64e3",
      "b57a24e7a0c8409fa1ac0ccf4a6d2e3c",
      "b32d3160832f41f1b7162bc3205b30a9",
      "ec2bc0a96d2e4accafa66f31746eed54",
      "c5de8123a5074430ba622e91c9d2e166",
      "9ca1e8c6de824cfbb1cbab38e8367156",
      "6876c0557bb042b6bc06fa35d56409ae",
      "25780b5379164d86a0fb12f1786c16e1",
      "1f0baf8dce3d40d99326bbcb7c1d1368",
      "4a1c72dcf94f42a795419f0a18a1608a",
      "41784fb7962041c4a03ae5e708f88b0e",
      "860bfb6df8f44d3ebba8b2b5dff3182f",
      "0b3b89bc07c14b3cba0142de4e2a44ee",
      "1490a6955db0479897a05082294d1cbb",
      "711765f84de7499cb5ac34d522e742a3",
      "6e500ce111084b54bae5c729b3066b3b",
      "7b22bac46edb4302adea7ba7777460f1",
      "75903c50430d4153a0e1ebc34c3cd3bb",
      "3872f3c9b98e44e58304b3e56b066681",
      "fb7928ec86ff4eea8287bc504c674072",
      "f4d12d43913a4de781174bf5d5d5cb69",
      "a5d577edd4ef4ebbba87d930906ba9a0",
      "d3beb0d4a9624dc8b6d2da27220c50c3",
      "80185be16e074e8e91940c120c06bfe4",
      "c97b87fc9f8f42fa9371898c06890742"
     ]
    },
    "id": "GK7157J6E_Nb",
    "outputId": "66a717cd-fd9a-4fda-8ee1-6d8f71bfe453"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import gradio as gr\n",
    "\n",
    "# ---- Model Setup ----\n",
    "model_id = \"google/medgemma-4b-it\"\n",
    "\n",
    "print(\"ðŸ”„ Loading pipeline...\")\n",
    "chatbot = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"google/medgemma-4b-it\",\n",
    "    torch_dtype=\"float32\",  # Change this from float16\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "\n",
    "# ---- Chat Function ----\n",
    "def chat_interface(message, history):\n",
    "    response = chatbot(\n",
    "    message,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.7,  # Lower = more stable\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.1,\n",
    "    do_sample=True,\n",
    ")[0][\"generated_text\"]\n",
    "\n",
    "    # Save history (optional)\n",
    "    with open(\"chat_history_medgemma_pipeline.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"User: {message}\\n\")\n",
    "        f.write(f\"Model: {response}\\n\\n\")\n",
    "\n",
    "    return response\n",
    "\n",
    "# ---- Gradio Chat Interface ----\n",
    "gr.ChatInterface(\n",
    "    fn=chat_interface,\n",
    "    title=\"ðŸ§  MedGemma 27B - Medical Chatbot\",\n",
    "    description=\"Ask medical or wellness-related questions.\",\n",
    ").queue().launch(debug=True, share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDhzioJo0ZtR"
   },
   "source": [
    "# DeepSeek Medical Reasoning\n",
    "- Device used to run the mode L4GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5414,
     "status": "ok",
     "timestamp": 1748955642686,
     "user": {
      "displayName": "Anjali Vaghjiani",
      "userId": "03778564321957104488"
     },
     "user_tz": -120
    },
    "id": "pS9EKzHc1V6R",
    "outputId": "09740ce3-53d0-4733-b37f-c5d7ccc532c3"
   },
   "outputs": [],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 92392,
     "status": "ok",
     "timestamp": 1748955736709,
     "user": {
      "displayName": "Anjali Vaghjiani",
      "userId": "03778564321957104488"
     },
     "user_tz": -120
    },
    "id": "D8ZfCxWU1MZS",
    "outputId": "5fa2bff4-baf9-4685-94a6-2454ddb0f295"
   },
   "outputs": [],
   "source": [
    "!pip install -U datasets accelerate peft trl bitsandbytes\n",
    "!pip install -U transformers==4.52.1\n",
    "!pip install huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9502,
     "status": "ok",
     "timestamp": 1748955746231,
     "user": {
      "displayName": "Anjali Vaghjiani",
      "userId": "03778564321957104488"
     },
     "user_tz": -120
    },
    "id": "MToxxAqK2M-L",
    "outputId": "b5ef9989-7474-433c-da19-6cdf7cd8f035"
   },
   "outputs": [],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "e08d062fd6bf48398bc7aa0d5d75b9aa",
      "f1004cf953c04c29a902c51098abb5f7",
      "2e7bc42cd6114d51909e41f3cb7304cd",
      "738dc112f0cd4b36bcf19ef45ce9e41f",
      "c100c2756b764f1094fd64a24d0dff1f",
      "ea851aa65eb74f35a1fa1e03a072523d",
      "71e577c3e0e0496ab6d39c78e660201e",
      "3ce45ea7b41444d0b8566d6dd2fe3416",
      "cf8435015e3d49dfb38a4717340b9b06",
      "af4102341c624710a11cffc6432b7315",
      "1ba5202fce304a09a1bf6150c040c44e",
      "4968ad7176f847f48f42b16aaf86417a",
      "31024451fb2340dc9173213094bae124",
      "2e597f1600284e75b006a0ad6f48774b",
      "a5082093b28d41a998c8c7261e62ae0c",
      "5d2be4174c7549929e05f28a391fa6d8",
      "d003aa5613914fe782d2e4b6da1d99d3",
      "d42afdd83d42474e84f4966455c5a469",
      "5e77af07bb214920b9786e1ac095dde2",
      "543e9efa4fc24c2f858e92bf5b8200ab",
      "86a066775e9c46f88a77e078c7dfd5e0",
      "9bfb508695954fbd95fbe87c4df65cc0",
      "12814ba250b843a3943900179f8580db",
      "faa1f491623c40589ec3dea30e2870b5",
      "1cd98d3eed734a1293b9a1f1ba02821b",
      "a796eb8a1c53438e98a5884feb8923a7",
      "81aeac1330eb484db0c4fa9b11528ae0",
      "176b89fb660b47d2ad230603a501a499",
      "34e9a8d094dc4f8db43a5575c4b44447",
      "983568a5ba424f09a3f0c186e955be59",
      "567fb6754719419c9b51a98552436580",
      "a7d40a0743674408b0ee5a1b7346dc3f",
      "6044a084ebdf40cc9356d77a32f7718c",
      "06971602e89d4e229d72db6d3c52835c",
      "b0968a95181d440db0af947a7ba13a85",
      "d4383c313a15418286ad9a2f79a00d1f",
      "ec867d46a877477f8c3f99e4cf09c48c",
      "8dde0e4630da4a688ab2e866b30138be",
      "d36b77beae4741348b728ec9661801db",
      "c02f8205585a430e8018585d95b24c75",
      "bda4277d0330480ca3f0574f1b96fb72",
      "ae1e264d6b594c4fbbcec449464ae4e3",
      "e95a174ab76d42aa9025c3e4f309dc8b",
      "b1ce1697cad34033a1f1a946a5eea581",
      "8117665265ef449baf7d8199542f46d0",
      "d7f392d4610941508d0f0a604f062e61",
      "c90f58aff10643a0b1c98089240c490b",
      "692ee5ce7b99472b9c680a3ec44e61e0",
      "d9a94eb07651462f881cfac7a4b3e496",
      "64b0a79e1ecd42df9a8e8a2a02c0ca7d",
      "b8c09b8554434cf697781c5406b13e92",
      "ecc627a7e2514e6e9d41a877592bf05c",
      "502ab5d9f87f41599d3fd9c39b709c51",
      "47ab1729bd5d40bab216a0eff6af3039",
      "385222ba1bee4390b7274bb36012b8eb",
      "b7f4656c15254a61bc102c47ca8cae79",
      "484b37a3ed7643f49093a11d43970aff",
      "a78ca9118b6041e791e67a1e110825e3",
      "baa4efd5dbda45efb1291e0fd06af417",
      "dc9a5bb3d80f42bdaabcc1acc7798148",
      "c205d2c94f2f4f838632893f2d7d35ba",
      "1f9b92cc05d64c3dae4dcdcaedc40856",
      "00af77d320a74ca89fc23bdb8e5acc2b",
      "18e6c98f1ac24f48a8fb2a9d181872ff",
      "0606e4a28ad44a649b1808be501d0f54",
      "82c16896b44042e5abe61e80da943f2f",
      "31e2bf54aa3e4f90923eecd778131ad0",
      "ee44a7917c0d4b0bb38aa9988c42b9f2",
      "bdf014a3d72d4e4ab2022756338019d3",
      "0da391e1569d4e1fade0ec1c645fbbc8",
      "1b4a8e03f1284c118951df33c9d99323",
      "7301f14ccdd248b49f41e005e532fa7a",
      "5ad2873104b34a4ca06ae6bf573eba2b",
      "b401daa9445949e7b9a7de057b3e1030",
      "4a13b7803f28444983502a0e10dfda07",
      "f27261368ae14d8eaa466321914fd6ac",
      "096033a5461346eaa87567f472957a7d",
      "9e8b5216579941049f30979df6189e05",
      "2f852f3c91c443089eea88f63a7a34ff",
      "239d10c99c7f4787aa1b864f1ec5922c",
      "127fb51fd3f14dd2b0438828d0cbaf5e",
      "19a960939be54f489078ec295edcce8b",
      "08387afef0fb4a7897ee11a098dfba71",
      "baa870d847a640cd81b4b3615ba264db",
      "cb7bad1879744518aead92671b5f4d08",
      "4c79bea897634144b62f5184be8ca630",
      "a7e7797bb9994d05b7c2f1e810919d0c",
      "e108b8c833834dee8d0141749a402d2f",
      "85b6d22f3b7b449bbb77ae6c78791f10",
      "76318aaa2dea4e3ab1a8bbce58d04b63",
      "ec0ebc9e6eff4c86ae925e11eefc4c5b",
      "84d3db706730407984b0b3ca6c974eab",
      "76848d60448c49c0ae23288642fdb0a5",
      "b7fb29477d884553a92fac5276a8daab",
      "66caadf86a3f4a36bf901aa4f5207acb",
      "3f82e721c877411f910d3b4376a37e4a",
      "8881f0ea3896402d8601c1bacca5995e",
      "2447a16a2abb420aa763dfd5e7509305",
      "24698c2764f74ddf805b38829defe9bb",
      "dbf14f69465a451b8ec8f1370a5e5ff7",
      "489b6dd8bfe24b1d90b46ab80d0d1ef0",
      "52500d8b96a245cfbe9910ad7e49c110",
      "8739582e970d4ab1aef3eafbd0258534",
      "14ff8da83463425bba9aa30f2fe56118",
      "76c267cc6d5040f980bfedb98ec3a764",
      "4ae9e65f81a7413285d7c3de0fa19620",
      "0189f6a4d9174a228290fd46a8d6b0dd",
      "e4d04cfaa74a41dab63a7113cffd26c3",
      "a887f63b4cdf4cdd8ba0b252e8021978",
      "363028f0072e406fb4e8b0f5f8e98e69",
      "9f01e86dd5a045b6b1199b9c14603e8d",
      "f41455c428d34eb7a28cb145500782cf",
      "4092a97a14af4b4bb91a17ded56e2e73",
      "6b73136e483c4f6f95a3fc4f88b58069",
      "17f4eafb285b43f9b3ee75d94304fe41",
      "536d2a4bd8224f0aa594ebb3a8467e2d",
      "ba4482aa6af443828af6e0dfda4daaf2",
      "8c1d4642441b4fda8328dfc0032a6186",
      "c029567760e24900b0f440bbcb351d70",
      "417f17186cec4ae39371f0ee3dabbaf5",
      "fd1eebdd1811474380663e712d3254b1",
      "b61c1486c0da4b65b824c66f385fc381",
      "82a3d6248f7a4abfa0febf6deeed9b2c",
      "525efe663bf347f08781e49fa4dfdc5f",
      "c90a4f036de34972ace17d13985d96b0",
      "ca2a2ddd20e34bf5b26bba9520476ca5",
      "610f7f7189e14d0e8fb7267debc83439",
      "90e690e998bd48f48eec005a76e0d250",
      "b6f5ad557f924997b506e46ccbc30a92",
      "b83807354ae246799d4dc251398ab4c2",
      "ba282a599a1044cd9dce772d0a9e1216",
      "6438fe9e0a9d4c40bad26fe3cc3de838"
     ]
    },
    "id": "2NbzpbKs09qN",
    "outputId": "314bb712-406e-406e-d89a-88c211d580f3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import gradio as gr\n",
    "\n",
    "# Load model & tokenizer\n",
    "model_id = \"kingabzpro/DeepSeek-R1-0528-Qwen3-8B-Medical-Reasoning\"\n",
    "\n",
    "print(\"ðŸ”„ Loading tokenizer and model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,  # or torch.float32 if you get NaN/Inf errors\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Chat function\n",
    "def chat_interface(message, history):\n",
    "    prompt = message\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        do_sample=True,\n",
    "        repetition_penalty=1.1,\n",
    "    )\n",
    "\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Optional: save chat history\n",
    "    with open(\"chat_history_deepseek.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"User: {message}\\nModel: {response}\\n\\n\")\n",
    "\n",
    "    return response\n",
    "\n",
    "# Gradio interface\n",
    "gr.ChatInterface(\n",
    "    fn=chat_interface,\n",
    "    title=\"ðŸ§  DeepSeek Qwen3 8B - Medical Reasoning Chatbot\",\n",
    "    description=\"Ask medical reasoning or clinical diagnostic questions.\"\n",
    ").queue().launch(debug=True, share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilXD_-69cJ15"
   },
   "source": [
    "# BioMistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 85148,
     "status": "ok",
     "timestamp": 1748965731508,
     "user": {
      "displayName": "Anjali Vaghjiani",
      "userId": "03778564321957104488"
     },
     "user_tz": -120
    },
    "id": "U0GyrD8WctMe",
    "outputId": "571e83ac-f9bb-4666-8974-279df489c0fa"
   },
   "outputs": [],
   "source": [
    "!pip install transformers accelerate gradio torch\n",
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 869,
     "referenced_widgets": [
      "963d5290a3e74c6699a942e8a3bdaa09",
      "70f576cd880d4ffdbcf1603eaddb22f5",
      "1d584d2451b64df39d359d8d2c512f42",
      "25f11f67b563477ca6f49ff0c6650fef",
      "5fd9d0e30deb460ea7e7e2cd126418e3",
      "17478544795749bcbf325d7af082d1d8",
      "d5883d6f14ad44a2b475783480a8569a",
      "d63984cef7a74156969395ec2d523e50",
      "42491cdf745e4eabbade526c4fc18f4d",
      "37d5d793254644889eb9560d94be9a1c",
      "36ef22262f62451faa9cb23ebb4b9b19",
      "597b26163e7d42febce8722e795b30f6",
      "f8509f66d2d2488b941428775a23c81f",
      "1249fa62321b47adb9c5b839ee51a1ac",
      "cf3d705d54514600863fe1f0a2df3a01",
      "da729d4b19244901892320d72521dd32",
      "15e649baaec349bc93f0fc0b064c6b2c",
      "bc10b21c69ec4833a7801d4aa8c3c292",
      "369f34bad6b44e969f8bab33014fc8bd",
      "69b6d890e9bc42f8b73396314eb3964a",
      "cc7dee2989974f5f8375faa2fa289549",
      "a4a3b5594b764f719ec21630cc9e37d5",
      "cccbf79eac8b4dd1a8216de92ad5a745",
      "882facbbb0e7490f926ef60623617ae1",
      "c7a5c03f60a8491ca626c334a032ea13",
      "8972d3231f704e9288c922ecec49657b",
      "ef8bcf7afd024f14b6cbd51b3ec414b1",
      "fb7596c36db04c4bae012cc817e9437c",
      "f498e2acd9ac4cad9337b9ed95b5a8dd",
      "8af6c54b2d3b4761b3a6f130f0802d82",
      "62059ea03eb045d0a628e23ee7323997",
      "f39d80b382d0484ca1c803ed2753227c",
      "0121c26e5d5248c0bc05d62374cfe39e",
      "b725769a03f64b7f9f0532138b5d1c34",
      "2dbe6e559c79412b8f224a4975218d1b",
      "c4ce70cecab44b89a8d8eb3613dd4f52",
      "eb358f7060704052a8ee609c709f06db",
      "27cd9b0e4f994e32af69ccf20aaa7394",
      "300465a95ce843309f3d3d1ad6981d96",
      "871d3ff5e7524a3b89587a22df7aa279",
      "cf5508f2c2274e1fb919d9e6ef913a8f",
      "9d35ed43b17e4ea28ebdac17f534049b",
      "31321e9e9a0d4ae28cb02da504924e64",
      "a8bd99b7ea1c478c9c16e8ddf65834cc",
      "d9cfcad623924338ac0dad3990145565",
      "648e579a537049cfa2c822a9b299e2ad",
      "8c4a2ab6e7a64b6d856f30c7f8b7f003",
      "b93377745195484281e37c75c1c17e8a",
      "091958ab57d64b5081d7bc5702d050d2",
      "3b97b6809a46469ba354c00c733aec40",
      "709593c5e6a441d08a43403e0a9e1b4d",
      "a9216dd80731494da66b3d9c384f4fca",
      "81276f5ac1ab4ab6a1ffd6aaf5478e2d",
      "4c52040ab24549059475d4127252464d",
      "f70012f41afc4d09b7ea880df3c65f51",
      "44b46dcc1557440283eb8fee2cacdf49",
      "17612a825e1b4aeaa70b38aa921038b1",
      "2c177f7aeec5474cae9b9e29b72c3aa5",
      "769ea0f655f946479d3b7f9abe9c06eb",
      "724042dda1224a19a2447f5d4a3572a7",
      "2cc0891de9e74527846a5ca4edd91322",
      "4084275a62664d16aae403e4de01f142",
      "5c1043ce28e945eba22670925ec8f56a",
      "a5b85df1299d4a2f921879784670384e",
      "dd35452f8de04245879eb04cf9cef831",
      "2c14b25ed9124dd08bce4635c3e8d4f7",
      "b9ae785165e14fdfaa65926e391b073f",
      "fa41e39c6f6b4c7f81cb830789a8c874",
      "8a6c8c5b1ddf4547bae1e76294251002",
      "22d99ef1fbd24e489355e6aabbf1500e",
      "ffccf4ee6f0e47ce8af559735c7bb2fa",
      "e519c6cbdbed42cfaef759b9e2cc6480",
      "3393d15168744bd2a57897b61bf6d978",
      "9ba92df6b5d64c258dbab6a3e2e97540",
      "c68c3d463cda44a69f450697bcc54282",
      "5e04c7319bc342a199aefbcd50540cdf",
      "c3a2cee9d846443d89a02c9e99cca430"
     ]
    },
    "id": "7mi9tf-2cI-m",
    "outputId": "27c689f9-61d0-4bab-8bc3-9d7b42def0d6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import gradio as gr\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_id = \"BioMistral/BioMistral-7B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.eval()\n",
    "\n",
    "# Chat function with history\n",
    "def chat_interface(message, history):\n",
    "    # Format prompt with history\n",
    "    prompt = \"\"\n",
    "    for user_input, bot_output in history:\n",
    "        prompt += f\"<s>[INST] {user_input} [/INST] {bot_output} </s>\\n\"\n",
    "    prompt += f\"<s>[INST] {message} [/INST]\"\n",
    "\n",
    "    # Tokenize and generate\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=512,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            repetition_penalty=1.1,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract latest response\n",
    "    if \"[/INST]\" in decoded_output:\n",
    "        response = decoded_output.split(\"[/INST]\")[-1].strip()\n",
    "    else:\n",
    "        response = decoded_output.strip()\n",
    "\n",
    "    return response\n",
    "\n",
    "# Gradio chat app\n",
    "gr.ChatInterface(\n",
    "    fn=chat_interface,\n",
    "    title=\"ðŸ§¬ BioMistral 7B - Biomedical Chatbot\",\n",
    "    description=\"Ask medical and biomedical questions. Powered by BioMistral-7B.\",\n",
    ").launch(debug=True, share=True)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOHWjTiBQ4PyEKg36CWqUHF",
   "gpuType": "T4",
   "mount_file_id": "160L8ZkqbBQac84dKxP0_dlSfONCvFDHC",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
