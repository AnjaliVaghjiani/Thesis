{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJ2IZnY0spOf",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQs-1g9pO2vc"
      },
      "source": [
        "# ContactDoctor Bio Medical LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zBB_GqePIUt",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers accelerate bitsandbytes gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8Eu1zo5Q2Z54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets"
      ],
      "metadata": {
        "id": "-B9Uv4jEPLeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the data from the file to train the model"
      ],
      "metadata": {
        "id": "B3npJmgHqYnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "data = [\n",
        "    {\"input\": \"i have a data\\nTotal Steps: 75000\\nAverage Zone Minutes: 90\\nAverage Heart Rate: 72 bpm\\nfood consumption of the week: varied, but often feel bloated\\nSleep activity for the week: 7 hours avg, generally good\\nPhysical activities performed for the week: walking, some yoga\\n\\nPlease provide:\\n1. Food Recommendation\\n2. Physical Exercise\\n3. Social Wellbeing Recommendation\\n4. Overall Suggestion\",\"output\": \"1. Food Recommendation:\\n- Your **varied** diet is a good foundation, but the symptom of often feeling **bloated** suggests a need to investigate specific food sensitivities or eating habits.\\n- **Keep a Food Diary:** For a week or two, track what you eat and when you experience bloating. This can help identify trigger foods.\\n- **Slow Down Eating:** Eat slowly and mindfully, chewing your food thoroughly. Rushing can lead to swallowing air and bloating.\\n- **Limit Gas-Producing Foods (initially):** Temporarily reduce intake of common culprits like beans, lentils, broccoli, cabbage, and carbonated drinks. Reintroduce them slowly to see what you tolerate.\\n- **Consider Probiotics:** Incorporate fermented foods (yogurt, kefir, sauerkraut) or a probiotic supplement to support gut health.\\n- **Stay Hydrated:** Adequate water intake aids digestion and can prevent constipation, a cause of bloating.\\n\\n2. Physical Exercise:\\n- Your **Total Steps: 75000** and **Average Zone Minutes: 90** indicate a good level of moderate activity (walking, some yoga). Your **Average Heart Rate of 72 bpm** is healthy.\\n- **Increase Intensity Gradually:** While consistent, consider adding short bursts of more intense activity within your walks to boost your cardiovascular fitness further and increase your **Zone Minutes**.\\n- **Incorporate Strength Training:** Adding 2-3 sessions of strength training per week will build muscle, improve metabolism, and support bone health, complementing your current activities.\\n- **Explore Different Yoga Styles:** If you're comfortable, try different yoga styles (e.g., Vinyasa, Power Yoga) to challenge your body in new ways and potentially aid digestion through specific poses.\\n\\n3. Social Wellbeing Recommendation:\\n- Your data doesn't directly indicate social wellbeing issues, and your **7 hours avg, generally good** sleep is a positive sign for overall energy levels to engage socially.\\n- **Leverage Your Activities:** Consider joining a yoga studio or a walking group. This is a great way to meet like-minded people and integrate social interaction with your physical activities.\\n- **Plan Regular Social Connections:** Even if you feel generally good, proactively scheduling time with friends and family can enhance your sense of belonging and reduce stress.\\n- **Practice Mindful Socializing:** Be present during interactions and avoid distractions, which can deepen connections.\\n\\n4. Overall Suggestion:\\n- Your primary focus should be on addressing the **bloating and digestive discomfort**, as this can significantly impact your daily comfort and nutrient absorption. Your exercise and sleep habits are generally positive, providing a good foundation.\\n- **Digestive Health First:** Work on identifying and managing the causes of your bloating through dietary adjustments and possibly consulting a healthcare professional or registered dietitian.\\n- **Mindful Eating Practices:** Beyond what you eat, how you eat (slowly, without distractions) is crucial for digestion.\\n- **Holistic Wellness:** Continue your balanced approach to physical activity. The combination of walking and yoga is beneficial for both physical and mental health, which can indirectly support digestive health.\\n- **Listen to Your Body's Cues:** Pay attention not just to major symptoms but also to subtle signals your body gives you regarding food and activity.\"}\n",
        "]\n",
        "\n",
        "dataset = Dataset.from_list(data)\n"
      ],
      "metadata": {
        "id": "rLUmuiVkqYD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "from datasets import Dataset\n",
        "from datasets import load_dataset\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "# === Step 1: Model & Tokenizer Setup ===\n",
        "model_id = \"AnjaliNV/WellBeing_LLM\"  # or base model like \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "\n",
        "print(\"üîÑ Loading tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token  # Required for some models\n",
        "\n",
        "print(\"üìÇ Loading local dataset...\")\n",
        "dataset = load_dataset(\"json\", data_files=\"/content/fitness-chat-prompt-completion-dataset.json\")  # Update path\n",
        "# Using the dataset created in the previous cell\n",
        "\n",
        "\n",
        "\n",
        "def preprocess(batch):\n",
        "    texts = [f\"### Question: {p}\\n### Answer: {c}\" for p, c in zip(batch[\"instruction\"], batch[\"output\"])]\n",
        "    tokens = tokenizer(texts, truncation=True, padding=\"max_length\", max_length=512)\n",
        "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n",
        "    return tokens\n",
        "\n",
        "\n",
        "\n",
        "print(\"üîÑ Tokenizing dataset...\")\n",
        "# Process without batching to avoid potential issues with padding/truncation in batches\n",
        "tokenized_dataset = dataset[\"train\"].map(preprocess, batched=True)\n",
        "\n",
        "\n",
        "\n",
        "# === Step 2: Load Quantized Base Model ===\n",
        "print(\"üîÑ Loading base model...\")\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True,\n",
        "    quantization_config=bnb_config,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# === Step 3: Inject LoRA ===\n",
        "print(\"üß† Adding LoRA adapters...\")\n",
        "peft_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.CAUSAL_LM\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# === Step 4: Set Up Trainer ===\n",
        "print(\"‚öôÔ∏è Preparing trainer...\")\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./WellBeing_LLM_finetuned\",\n",
        "    per_device_train_batch_size=1,      # lowered batch size\n",
        "    gradient_accumulation_steps=8,      # to keep effective batch size\n",
        "    num_train_epochs=3,\n",
        "    logging_steps=10,\n",
        "    save_steps=100,\n",
        "    save_total_limit=1,\n",
        "    learning_rate=3e-4,\n",
        "    fp16=True,\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    report_to=[],\n",
        ")\n",
        "\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# === Step 5: Train ===\n",
        "print(\"üöÄ Starting training...\")\n",
        "trainer.train()\n",
        "\n",
        "# === Step 6: Save Final Model + Tokenizer ===\n",
        "print(\"üíæ Saving the fine-tuned model...\")\n",
        "trainer.save_model(\"./WellBeing_LLM_finetuned\")\n",
        "tokenizer.save_pretrained(\"./WellBeing_LLM_finetuned\")"
      ],
      "metadata": {
        "id": "k0AWAIyXN0uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "\n",
        "base_model_id = \"ContactDoctor/Bio-Medical-Llama-3-8B\"\n",
        "adapter_path = \"AnjaliNV/WellBeing_LLM\"\n",
        "\n",
        "# Optional: Enable 4-bit quantization to reduce memory usage\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
        "\n",
        "# Load model with quantization and low memory footprint\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_id,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True,\n",
        "    quantization_config=bnb_config,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# Load the LoRA adapter (AFTER the base model is on device)\n",
        "model = PeftModel.from_pretrained(model, adapter_path)\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "B-kSkpUK_dDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel\n",
        "from transformers import AutoTokenizer\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "# Optional: If running in Colab/Jupyter\n",
        "# notebook_login()\n",
        "\n",
        "repo_name = \"AnjaliNV/WellBeing_LLM\"  # Choose a name\n",
        "\n",
        "# Push the LoRA adapter\n",
        "model.push_to_hub(repo_name)\n",
        "tokenizer.push_to_hub(repo_name)\n"
      ],
      "metadata": {
        "id": "wf10JbVZ6CLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG fine tuning"
      ],
      "metadata": {
        "id": "jJQyIxhw-gyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain faiss-cpu sentence-transformers transformers\n"
      ],
      "metadata": {
        "id": "PaVHh0jR-kvv",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bQip4YCFKa4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3t4w4p6nK9CL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "vectorstore = FAISS.load_local(\n",
        "    \"/content/drive/MyDrive/rag_index\",\n",
        "    embeddings=embedding_model,\n",
        "    allow_dangerous_deserialization=True  # <- Add this line\n",
        ")\n"
      ],
      "metadata": {
        "id": "DganfMFKEXxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_split_document(filepath):\n",
        "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "    import PyPDF2\n",
        "\n",
        "    text = \"\"\n",
        "\n",
        "    if filepath.endswith(\".txt\"):\n",
        "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "            text = f.read()\n",
        "    elif filepath.endswith(\".pdf\"):\n",
        "        with open(filepath, \"rb\") as f:\n",
        "            reader = PyPDF2.PdfReader(f)\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format\")\n",
        "\n",
        "    # Split text into chunks\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    return splitter.split_text(text)\n",
        "\n",
        "new_chunks = load_and_split_document(\"/content/Physical_Exercise.txt\")  # or .txt\n",
        "vectorstore.add_texts(new_chunks)\n",
        "vectorstore.save_local(\"/content/drive/MyDrive/rag_index\")\n",
        "print(\"Vectorstore updated and saved.\")\n"
      ],
      "metadata": {
        "id": "wDobS1ltkYNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "\n",
        "def chat_rag_interface(message, history):\n",
        "    # Step 1: Retrieve relevant context chunks for the user question\n",
        "    retrieved_chunks = vectorstore.similarity_search(message, k=3)  # or however you implemented retrieval\n",
        "\n",
        "    # Step 2: Combine chunks into one context string\n",
        "    # context = \"\\n\".join(retrieved_chunks)\n",
        "    context = \"\\n\".join([doc.page_content for doc in retrieved_chunks])\n",
        "\n",
        "    # Step 3: Build prompt with context + user message\n",
        "    prompt_template = f\"\"\"\n",
        "You are a wellbeing expert. Use the provided CONTEXT to answer the USER DATA in the format shown below.\n",
        "\n",
        "Always respond under the following 4 sections using bullet points where specified:\n",
        "1. Food Recommendation\n",
        "2. Physical Exercise\n",
        "3. Sleep and Recovery\n",
        "4. Overall Suggestion\n",
        "\n",
        "Use the following guidelines when analyzing a user's Average Zone Minutes:\n",
        "\n",
        "- Zone Minutes < 90: Recommend starting with low-impact activities.\n",
        "- Zone Minutes 90‚Äì150: Encourage maintaining current activity with gradual progression.\n",
        "- Zone Minutes > 150: Recommend advanced workouts and advise on recovery.\n",
        "\n",
        "Use this logic in every response.\n",
        "\n",
        "CONTEXT:\n",
        "{context}\n",
        "\n",
        "---\n",
        "\n",
        "Example:\n",
        "User Data:\n",
        "Total Steps: 100,000\n",
        "Average Zone Minutes: 160\n",
        "Average Heart Rate: 60 bpm\n",
        "Food Consumption: healthy\n",
        "Sleep: 7.5 hrs average\n",
        "Physical Activities: running, gym\n",
        "\n",
        "Response:\n",
        "1. Food Recommendation: Your food intack is already healty, try different varities of food\n",
        "   a) Protein Intake: Include lean meats, fish, tofu, or legumes to support muscle repair.\n",
        "   b) Healthy Fats: Add avocados, olive oil, almonds, walnuts, and chia seeds.\n",
        "   c) Vegetable Variety: Eat spinach, broccoli, carrots, and zucchini for essential vitamins.\n",
        "   d) Hydration: Aim for 3‚Äì4 liters of water per day to stay well-hydrated.\n",
        "\n",
        "2. Physical Exercise:\n",
        "   You have good cardiovascual fitness from running. Along with walking you can include\n",
        "   a) Strength training:- squats, deadlifts, bench press, and overhead press.\n",
        "   b) Yoga or Pilates\n",
        "   c) Outdoor Activities/Adventure Sports:- Cycling, tracking, swimming.\n",
        "\n",
        "3. Sleep and Recovery:\n",
        "   Aim for 7‚Äì8 hours of sleep. Avoid screens before bed and follow a consistent schedule.\n",
        "\n",
        "4. Overall Suggestion:\n",
        "   Great job! Keep up the consistency. You could also explore group fitness or meditation for balance.\n",
        "\n",
        "---\n",
        "\n",
        "User Data:\n",
        "{message}\n",
        "\n",
        "Response:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    # Step 4: Tokenize and generate answer from your model\n",
        "    inputs = tokenizer(prompt_template, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=512,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        do_sample=True,\n",
        "        repetition_penalty=1.2,\n",
        "    )\n",
        "\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    generated_text = response[len(prompt_template):].strip()\n",
        "\n",
        "    # Optional: Save chat history\n",
        "    with open(\"chat_history.txt\", \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(f\"User: {message}\\n\")\n",
        "        f.write(f\"Model: {generated_text}\\n\\n\")\n",
        "\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "k7wnP4RbFqy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.ChatInterface(\n",
        "    fn=chat_rag_interface,\n",
        "    title=\"Well Being Advicer\",\n",
        "    description=\"Receive holistic health advice grounded in domain knowledge.\",\n",
        ").queue().launch(debug=True, share=True)\n"
      ],
      "metadata": {
        "id": "jaP6Sr2aFr4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# Load the saved model and tokenizer\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"WellBeing_LLM\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"WellBeing_LLM\")\n",
        "\n",
        "# Push to HF Hub\n",
        "model.push_to_hub(\"WellBeing_LLM\")        # this creates a repo under your username\n",
        "tokenizer.push_to_hub(\"WellBeing_LLM\")\n"
      ],
      "metadata": {
        "id": "1bef4WCRaPI8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "https://github.com/AnjaliVaghjiani/Thesis/blob/main/ContactDoctor.ipynb",
      "authorship_tag": "ABX9TyOmhj9yFUejCigRnf9vQgz6"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}